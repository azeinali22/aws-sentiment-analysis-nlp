{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "In this Project, you will bring together many of the tools and techniques that you have learned throughout this course into a final project. You can choose from many different paths to get to the solution. \n",
    "\n",
    "### Business scenario\n",
    "\n",
    "You work for a training organization that recently developed an introductory course about machine learning (ML). The course includes more than 40 videos that cover a broad range of ML topics. You have been asked to create an application that will students can use to quickly locate and view video content by searching for topics and key phrases.\n",
    "\n",
    "You have downloaded all of the videos to an Amazon Simple Storage Service (Amazon S3) bucket. Your assignment is to produce a dashboard that meets your supervisor’s requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project steps\n",
    "\n",
    "To complete this project, you will follow these steps:\n",
    "\n",
    "1. [Viewing the video files](#1.-Viewing-the-video-files)\n",
    "2. [Transcribing the videos](#2.-Transcribing-the-videos)\n",
    "3. [Normalizing the text](#3.-Normalizing-the-text)\n",
    "4. [Extracting key phrases and topics](#4.-Extracting-key-phrases-and-topics)\n",
    "5. [Creating the dashboard](#5.-Creating-the-dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information\n",
    "\n",
    "The following cell contains some information that might be useful as you complete this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"c56161a939430l3396553t1w744137092661-labbucket-rn642jaq01e9\"\n",
    "job_data_access_role = 'arn:aws:iam::744137092661:role/service-role/c56161a939430l3396553t1w7-ComprehendDataAccessRole-1P24MSS91ADHP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Viewing the video files\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source video files are located in the following shared Amazon Simple Storage Service (Amazon S3) bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26 20:17:33  410925369 Mod01_Course Overview.mp4\n",
      "2021-04-26 20:10:02   39576695 Mod02_Intro.mp4\n",
      "2021-04-26 20:31:23  302994828 Mod02_Sect01.mp4\n",
      "2021-04-26 20:17:33  416563881 Mod02_Sect02.mp4\n",
      "2021-04-26 20:17:33  318685583 Mod02_Sect03.mp4\n",
      "2021-04-26 20:17:33  255877251 Mod02_Sect04.mp4\n",
      "2021-04-26 20:23:51   99988046 Mod02_Sect05.mp4\n",
      "2021-04-26 20:24:54   50700224 Mod02_WrapUp.mp4\n",
      "2021-04-26 20:26:27   60627667 Mod03_Intro.mp4\n",
      "2021-04-26 20:26:28  272229844 Mod03_Sect01.mp4\n",
      "2021-04-26 20:27:06  309127124 Mod03_Sect02_part1.mp4\n",
      "2021-04-26 20:27:06  195635527 Mod03_Sect02_part2.mp4\n",
      "2021-04-26 20:28:03  123924818 Mod03_Sect02_part3.mp4\n",
      "2021-04-26 20:31:28  171681915 Mod03_Sect03_part1.mp4\n",
      "2021-04-26 20:32:07  285200083 Mod03_Sect03_part2.mp4\n",
      "2021-04-26 20:33:17  105470345 Mod03_Sect03_part3.mp4\n",
      "2021-04-26 20:35:10  157185651 Mod03_Sect04_part1.mp4\n",
      "2021-04-26 20:36:27  187435635 Mod03_Sect04_part2.mp4\n",
      "2021-04-26 20:36:40  280720369 Mod03_Sect04_part3.mp4\n",
      "2021-04-26 20:40:01  443479313 Mod03_Sect05.mp4\n",
      "2021-04-26 20:40:08  234182186 Mod03_Sect06.mp4\n",
      "2021-04-26 20:40:33  207718047 Mod03_Sect07_part1.mp4\n",
      "2021-04-26 20:42:07  125592110 Mod03_Sect07_part2.mp4\n",
      "2021-04-26 20:45:10  508500301 Mod03_Sect07_part3.mp4\n",
      "2021-04-26 20:46:16  320126756 Mod03_Sect08.mp4\n",
      "2021-04-26 20:46:43   41839508 Mod03_WrapUp.mp4\n",
      "2021-04-26 20:46:55   34148489 Mod04_Intro.mp4\n",
      "2021-04-26 20:48:24   84959465 Mod04_Sect01.mp4\n",
      "2021-04-26 20:48:25  345182970 Mod04_Sect02_part1.mp4\n",
      "2021-04-26 20:51:34  218661651 Mod04_Sect02_part2.mp4\n",
      "2021-04-26 20:53:32  430140637 Mod04_Sect02_part3.mp4\n",
      "2021-04-26 20:56:03   22036605 Mod04_WrapUp.mp4\n",
      "2021-04-26 20:57:18   49187118 Mod05_Intro.mp4\n",
      "2021-04-26 20:58:19  245798071 Mod05_Sect01_ver2.mp4\n",
      "2021-04-26 20:58:50  233314835 Mod05_Sect02_part1_ver2.mp4\n",
      "2021-04-26 20:59:14  348545306 Mod05_Sect02_part2.mp4\n",
      "2021-04-26 20:59:17  239142711 Mod05_Sect03_part1.mp4\n",
      "2021-04-26 21:06:04  267533559 Mod05_Sect03_part2.mp4\n",
      "2021-04-26 21:06:06  212502220 Mod05_Sect03_part3.mp4\n",
      "2021-04-26 21:06:48  206317022 Mod05_Sect03_part4_ver2.mp4\n",
      "2021-04-26 21:06:48   60361230 Mod05_WrapUp_ver2.mp4\n",
      "2021-04-26 21:09:14   35397860 Mod06_Intro.mp4\n",
      "2021-04-26 21:09:24  845633599 Mod06_Sect01.mp4\n",
      "2021-04-26 21:10:47  326126684 Mod06_Sect02.mp4\n",
      "2021-04-26 21:12:26   19790740 Mod06_WrapUp.mp4\n",
      "2021-04-26 21:12:56  131249036 Mod07_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install and configure the required Libraries and Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-02 09:14:17--  https://johnvansickle.com/ffmpeg/builds/ffmpeg-git-amd64-static.tar.xz\n",
      "Resolving johnvansickle.com (johnvansickle.com)... 107.180.57.212\n",
      "Connecting to johnvansickle.com (johnvansickle.com)|107.180.57.212|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 41964060 (40M) [application/x-xz]\n",
      "Saving to: ‘ffmpeg-git-amd64-static.tar.xz.2’\n",
      "\n",
      "100%[======================================>] 41,964,060  35.0MB/s   in 1.1s   \n",
      "\n",
      "2025-04-02 09:14:19 (35.0 MB/s) - ‘ffmpeg-git-amd64-static.tar.xz.2’ saved [41964060/41964060]\n",
      "\n",
      "/home/ec2-user/SageMaker/ffmpeg-git-20240629-amd64-static\n",
      "ffmpeg version N-71064-gd5e603ddc0-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2024 the FFmpeg developers\n",
      "built with gcc 8 (Debian 8.3.0-6)\n",
      "configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "libavutil      59. 27.100 / 59. 27.100\n",
      "libavcodec     61.  9.100 / 61.  9.100\n",
      "libavformat    61.  4.100 / 61.  4.100\n",
      "libavdevice    61.  2.100 / 61.  2.100\n",
      "libavfilter    10.  2.102 / 10.  2.102\n",
      "libswscale      8.  2.100 /  8.  2.100\n",
      "libswresample   5.  2.100 /  5.  2.100\n",
      "libpostproc    58.  2.100 / 58.  2.100\n"
     ]
    }
   ],
   "source": [
    "# FFmpeg installation\n",
    "!wget https://johnvansickle.com/ffmpeg/builds/ffmpeg-git-amd64-static.tar.xz\n",
    "!tar -xf ffmpeg-git-amd64-static.tar.xz\n",
    "%cd ffmpeg-git-20240629-amd64-static\n",
    "!sudo mv ffmpeg /usr/local/bin/\n",
    "!sudo mv ffprobe /usr/local/bin/\n",
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ju_xlhkq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ju_xlhkq\n",
      "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai-whisper==20240930) (10.6.0)\n",
      "Requirement already satisfied: numba in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai-whisper==20240930) (0.61.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai-whisper==20240930) (1.26.4)\n",
      "Collecting tiktoken (from openai-whisper==20240930)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch (from openai-whisper==20240930)\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai-whisper==20240930) (4.67.1)\n",
      "Collecting triton>=2 (from openai-whisper==20240930)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from numba->openai-whisper==20240930) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.4)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (2025.2.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting sympy==1.13.1 (from torch->openai-whisper==20240930)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
      "Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m133.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803707 sha256=fe058ed8fb4929f618a347ad60da61fdd2112d71e605b9573fa4f0ab5838bdf0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-47zkpatx/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, openai-whisper\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-whisper-20240930 sympy-1.13.1 tiktoken-0.9.0 torch-2.6.0 triton-3.2.0\n",
      "Collecting rake_nltk\n",
      "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rake_nltk) (3.9.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.67.1)\n",
      "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: rake_nltk\n",
      "Successfully installed rake_nltk-1.0.6\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m145.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.1\n",
      "    Uninstalling scipy-1.15.1:\n",
      "      Successfully uninstalled scipy-1.15.1\n",
      "Successfully installed gensim-4.3.3 scipy-1.13.1 smart-open-7.1.0\n"
     ]
    }
   ],
   "source": [
    "# Install necessary Python libraries\n",
    "# These are used for audio processing, transcription, and keyword/topic extraction\n",
    "\n",
    "!pip install pydub                       # For handling audio segments\n",
    "!pip install git+https://github.com/openai/whisper.git  # OpenAI's Whisper for transcription\n",
    "!pip install rake_nltk                  # RAKE algorithm for key phrase extraction\n",
    "!pip install gensim                     # For LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# AWS SDK\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Audio transcription and NLP tools\n",
    "import whisper\n",
    "from rake_nltk import Rake\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# NLTK for tokenization, lemmatization, and stopword filtering\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transcribing the videos\n",
    " ([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to implement your solution to transcribe the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy videos to my S3 bucket...\n",
      "⚙️ Processing file: datasource/Mod01_Course Overview.mp4\n",
      "⚙️ Processing file: datasource/Mod02_Intro.mp4\n",
      "⚙️ Processing file: datasource/Mod02_Sect01.mp4\n",
      "⚙️ Processing file: datasource/Mod02_Sect02.mp4\n",
      "⚙️ Processing file: datasource/Mod02_Sect03.mp4\n",
      "⚙️ Processing file: datasource/Mod02_Sect04.mp4\n",
      "⚙️ Processing file: datasource/Mod02_Sect05.mp4\n",
      "⚙️ Processing file: datasource/Mod02_WrapUp.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Intro.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect01.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect02_part1.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect02_part2.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect02_part3.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect03_part1.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect03_part2.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect03_part3.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect04_part1.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect04_part2.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect04_part3.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect05.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect06.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect07_part1.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect07_part2.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect07_part3.mp4\n",
      "⚙️ Processing file: datasource/Mod03_Sect08.mp4\n",
      "⚙️ Processing file: datasource/Mod03_WrapUp.mp4\n",
      "⚙️ Processing file: datasource/Mod04_Intro.mp4\n",
      "⚙️ Processing file: datasource/Mod04_Sect01.mp4\n",
      "⚙️ Processing file: datasource/Mod04_Sect02_part1.mp4\n",
      "⚙️ Processing file: datasource/Mod04_Sect02_part2.mp4\n",
      "⚙️ Processing file: datasource/Mod04_Sect02_part3.mp4\n",
      "⚙️ Processing file: datasource/Mod04_WrapUp.mp4\n",
      "⚙️ Processing file: datasource/Mod05_Intro.mp4\n",
      "⚙️ Processing file: datasource/Mod05_Sect01_ver2.mp4\n",
      "⚙️ Processing file: datasource/Mod05_Sect02_part1_ver2.mp4\n",
      "⚙️ Processing file: datasource/Mod05_Sect02_part2.mp4\n",
      "⚙️ Processing file: datasource/Mod05_Sect03_part1.mp4\n",
      "⚙️ Processing file: datasource/Mod05_Sect03_part2.mp4\n",
      "⚙️ Processing file: datasource/Mod05_Sect03_part3.mp4\n",
      "⚙️ Processing file: datasource/Mod05_Sect03_part4_ver2.mp4\n",
      "⚙️ Processing file: datasource/Mod05_WrapUp_ver2.mp4\n",
      "⚙️ Processing file: datasource/Mod06_Intro.mp4\n",
      "⚙️ Processing file: datasource/Mod06_Sect01.mp4\n",
      "⚙️ Processing file: datasource/Mod06_Sect02.mp4\n",
      "⚙️ Processing file: datasource/Mod06_WrapUp.mp4\n",
      "⚙️ Processing file: datasource/Mod07_Sect01.mp4\n",
      "✅ All MP4 files already exist in the destination bucket.\n",
      "________________________________________________\n",
      "Convert MP4 to WAV and store in S3...\n",
      "✅ datasource/Mod01_Course Overview.mp4 WAV is already exists.\n",
      "✅ datasource/Mod02_Intro.mp4 WAV is already exists.\n",
      "✅ datasource/Mod02_Sect01.mp4 WAV is already exists.\n",
      "✅ datasource/Mod02_Sect02.mp4 WAV is already exists.\n",
      "✅ datasource/Mod02_Sect03.mp4 WAV is already exists.\n",
      "✅ datasource/Mod02_Sect04.mp4 WAV is already exists.\n",
      "✅ datasource/Mod02_Sect05.mp4 WAV is already exists.\n",
      "✅ datasource/Mod02_WrapUp.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Intro.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect01.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect02_part1.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect02_part2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect02_part3.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect03_part1.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect03_part2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect03_part3.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect04_part1.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect04_part2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect04_part3.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect05.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect06.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect07_part1.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect07_part2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect07_part3.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_Sect08.mp4 WAV is already exists.\n",
      "✅ datasource/Mod03_WrapUp.mp4 WAV is already exists.\n",
      "✅ datasource/Mod04_Intro.mp4 WAV is already exists.\n",
      "✅ datasource/Mod04_Sect01.mp4 WAV is already exists.\n",
      "✅ datasource/Mod04_Sect02_part1.mp4 WAV is already exists.\n",
      "✅ datasource/Mod04_Sect02_part2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod04_Sect02_part3.mp4 WAV is already exists.\n",
      "✅ datasource/Mod04_WrapUp.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_Intro.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_Sect01_ver2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_Sect02_part1_ver2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_Sect02_part2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_Sect03_part1.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_Sect03_part2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_Sect03_part3.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_Sect03_part4_ver2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod05_WrapUp_ver2.mp4 WAV is already exists.\n",
      "✅ datasource/Mod06_Intro.mp4 WAV is already exists.\n",
      "✅ datasource/Mod06_Sect01.mp4 WAV is already exists.\n",
      "✅ datasource/Mod06_Sect02.mp4 WAV is already exists.\n",
      "✅ datasource/Mod06_WrapUp.mp4 WAV is already exists.\n",
      "✅ datasource/Mod07_Sect01.mp4 WAV is already exists.\n",
      "________________________________________________\n",
      "Transcribing audio files and save to JSON in S3...\n",
      "✅ Transcription JSON is already exists at s3://nlpprojectamirhossein/json/transcriptions.json\n",
      "🛑 Skipping transcription; JSON file already exists.\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Copy video to my S3 bucket -------------------\n",
    "print(\"Copy videos to my S3 bucket...\")\n",
    "\n",
    "# Initialize AWS S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Source and destination bucket details\n",
    "source_bucket_name = 'nlpprojectamirhossein'\n",
    "destination_bucket_name = 'nlpprojectamirhossein'\n",
    "destination_prefix = 'datasource/'\n",
    "\n",
    "# Track file status\n",
    "existing_files = []\n",
    "new_files_uploaded = False\n",
    "\n",
    "# Check if a file exists in the destination bucket\n",
    "def check_if_file_exists(destination_key):\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=destination_bucket_name, Key=destination_key)\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False\n",
    "        print(f'Error checking {destination_key}: {e}')\n",
    "        return False\n",
    "\n",
    "# Upload a file from source to destination bucket\n",
    "def upload_file_to_destination(file_key, destination_key):\n",
    "    global new_files_uploaded\n",
    "    try:\n",
    "        video_buffer = io.BytesIO()\n",
    "        s3_client.download_fileobj(Bucket=source_bucket_name, Key=file_key, Fileobj=video_buffer)\n",
    "        video_buffer.seek(0)\n",
    "        s3_client.upload_fileobj(video_buffer, Bucket=destination_bucket_name, Key=destination_key)\n",
    "        print(f'Uploaded {file_key} to s3://{destination_bucket_name}/{destination_key}')\n",
    "        new_files_uploaded = True\n",
    "    except ClientError as e:\n",
    "        print(f'Error uploading {file_key}: {e}')\n",
    "\n",
    "# Process each object in the source bucket\n",
    "def process_files(response):\n",
    "    global new_files_uploaded, existing_files\n",
    "    for obj in response.get('Contents', []):\n",
    "        file_key = obj['Key']\n",
    "        if file_key.endswith('.mp4'):\n",
    "            print(f'⚙️ Processing file: {file_key}')\n",
    "            destination_key = os.path.join(destination_prefix, os.path.basename(file_key))\n",
    "            if check_if_file_exists(destination_key):\n",
    "                existing_files.append(destination_key)\n",
    "            else:\n",
    "                upload_file_to_destination(file_key, destination_key)\n",
    "\n",
    "# Main function to list and process MP4 files\n",
    "def main():\n",
    "    response = s3_client.list_objects_v2(Bucket=source_bucket_name)\n",
    "    if 'Contents' in response:\n",
    "        process_files(response)\n",
    "\n",
    "    if not new_files_uploaded and existing_files:\n",
    "        print(\"✅ All MP4 files already exist in the destination bucket.\")\n",
    "    elif new_files_uploaded:\n",
    "        print(\"✅ New MP4 files have been successfully copied to the destination bucket.\")\n",
    "    else:\n",
    "        print(\"⚠️ No MP4 files were found in the source bucket.\")\n",
    "\n",
    "# Run main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# ------------------- Convert MP4 to WAV and store in S3 -------------------\n",
    "print(\"________________________________________________\")\n",
    "print(\"Convert MP4 to WAV and store in S3...\")\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Define bucket names and destination path\n",
    "source_bucket_name = 'nlpprojectamirhossein'\n",
    "destination_bucket_name = 'nlpprojectamirhossein'\n",
    "destination_prefix = 'converted_files/'\n",
    "\n",
    "# Collect already existing WAV files in destination bucket\n",
    "existing_files = set()\n",
    "response = s3_client.list_objects_v2(Bucket=destination_bucket_name, Prefix=destination_prefix)\n",
    "if 'Contents' in response:\n",
    "    existing_files = {obj['Key'] for obj in response['Contents']}\n",
    "\n",
    "# List MP4 files in the source bucket\n",
    "response = s3_client.list_objects_v2(Bucket=source_bucket_name)\n",
    "\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        file_key = obj['Key']\n",
    "        if not file_key.endswith('.mp4'):\n",
    "            continue\n",
    "\n",
    "        # Define WAV filename and full S3 destination key\n",
    "        wav_filename = os.path.basename(file_key).replace('.mp4', '.wav')\n",
    "        wav_s3_path = os.path.join(destination_prefix, wav_filename)\n",
    "\n",
    "        # Skip if WAV already exists\n",
    "        if wav_s3_path in existing_files:\n",
    "            print(f\"✅ {file_key} WAV is already exists.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"⚙️ Processing: {file_key}\")\n",
    "\n",
    "        # Define local file paths\n",
    "        local_video_path = f\"/tmp/{os.path.basename(file_key)}\"\n",
    "        output_wav_path = f\"/tmp/{wav_filename}\"\n",
    "\n",
    "        try:\n",
    "            # Download MP4 from S3\n",
    "            s3_client.download_file(Bucket=source_bucket_name, Key=file_key, Filename=local_video_path)\n",
    "            print(f\"Downloaded to {local_video_path}\")\n",
    "\n",
    "            # Convert MP4 to WAV using FFmpeg\n",
    "            ffmpeg_cmd = [\n",
    "                \"ffmpeg\",\n",
    "                \"-i\", local_video_path,\n",
    "                \"-vn\", \"-acodec\", \"pcm_s16le\",\n",
    "                \"-ar\", \"16000\", \"-ac\", \"1\",\n",
    "                output_wav_path\n",
    "            ]\n",
    "            process = subprocess.Popen(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            _, error = process.communicate()\n",
    "\n",
    "            if process.returncode != 0:\n",
    "                print(f\"❌ Conversion error for {file_key}: {error.decode()}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"✅ Conversion complete: {output_wav_path}\")\n",
    "\n",
    "            # Upload WAV to S3\n",
    "            s3_client.upload_file(output_wav_path, Bucket=destination_bucket_name, Key=wav_s3_path)\n",
    "            print(f\"✅ Uploaded to s3://{destination_bucket_name}/{wav_s3_path}\")\n",
    "\n",
    "        except ClientError as e:\n",
    "            print(f\"❌ AWS error for {file_key}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ General error for {file_key}: {e}\")\n",
    "        finally:\n",
    "            # Cleanup local files\n",
    "            for path in [local_video_path, output_wav_path]:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "else:\n",
    "    print(\"⚠️ No MP4 files found in the source bucket.\")\n",
    "\n",
    "# ------------------- Transcribe audio files and save to JSON in S3 -------------------\n",
    "print(\"________________________________________________\")\n",
    "print(\"Transcribing audio files and save to JSON in S3...\")\n",
    "\n",
    "# Initialize AWS S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Bucket configuration\n",
    "source_bucket_name = 'nlpprojectamirhossein'      # Where .wav files are stored\n",
    "destination_bucket_name = 'nlpprojectamirhossein' # Where the output JSON will be stored\n",
    "destination_prefix = 'json/'                      # Folder for JSON output in destination\n",
    "json_s3_key = os.path.join(destination_prefix, \"transcriptions.json\")\n",
    "\n",
    "# Check if transcription JSON already exists\n",
    "def check_json_exists():\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=destination_bucket_name, Key=json_s3_key)\n",
    "        print(f\"✅ Transcription JSON is already exists at s3://{destination_bucket_name}/{json_s3_key}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False\n",
    "        print(f\"⚠️ Error checking JSON file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Skip transcription if JSON exists\n",
    "if check_json_exists():\n",
    "    print(\"🛑 Skipping transcription; JSON file already exists.\")\n",
    "else:\n",
    "    # Load Whisper model for transcription\n",
    "    model = whisper.load_model(\"base\")  # You can change to \"small\", \"medium\", \"large\"\n",
    "\n",
    "    # List .wav files in source bucket\n",
    "    response = s3_client.list_objects_v2(Bucket=source_bucket_name)\n",
    "    transcriptions = {}\n",
    "\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            file_key = obj['Key']\n",
    "            if not file_key.endswith('.wav'):\n",
    "                continue\n",
    "\n",
    "            print(f\"⚙️ Transcribing: {file_key}\")\n",
    "            base_filename = os.path.basename(file_key)\n",
    "            audio_name = os.path.splitext(base_filename)[0]\n",
    "            local_audio_path = audio_name\n",
    "\n",
    "            try:\n",
    "                # Download WAV to local file\n",
    "                s3_client.download_file(Bucket=source_bucket_name, Key=file_key, Filename=local_audio_path)\n",
    "                print(f\"⬇️ Downloaded: {local_audio_path}\")\n",
    "\n",
    "                # Transcribe with Whisper\n",
    "                result = model.transcribe(local_audio_path)\n",
    "                transcriptions[audio_name] = result[\"text\"]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error transcribing {file_key}: {e}\")\n",
    "            finally:\n",
    "                if os.path.exists(local_audio_path):\n",
    "                    os.remove(local_audio_path)\n",
    "\n",
    "    # Save transcription JSON to S3\n",
    "    if transcriptions:\n",
    "        json_buffer = io.BytesIO()\n",
    "        json_buffer.write(json.dumps(transcriptions, indent=4).encode('utf-8'))\n",
    "        json_buffer.seek(0)\n",
    "\n",
    "        try:\n",
    "            s3_client.upload_fileobj(json_buffer, Bucket=destination_bucket_name, Key=json_s3_key)\n",
    "            print(f\"✅ Uploaded transcription JSON to s3://{destination_bucket_name}/{json_s3_key}\")\n",
    "        except ClientError as e:\n",
    "            print(f\"❌ Upload failed: {e}\")\n",
    "    else:\n",
    "        print(\"⚠️ No transcriptions were created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalizing the text\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to perform any text normalization steps that are necessary for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transcription JSON is downloaded from s3://nlpprojectamirhossein/json/transcriptions.json\n",
      "📄 Normalized transcription JSON is saved locally at /tmp/normalized_transcripts.json\n",
      "✅ Normalized transcription JSON is uploaded to s3://nlpprojectamirhossein/json/normalized_transcripts.json\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Normalize transcript text using NLTK -------------------\n",
    "\n",
    "# Initialize NLTK tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# S3 bucket and file paths\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'nlpprojectamirhossein'\n",
    "json_key = 'json/transcriptions.json'\n",
    "normalized_json_key = 'json/normalized_transcripts.json'\n",
    "\n",
    "# Text normalization pipeline\n",
    "def normalize_text_nltk(text):\n",
    "    \"\"\"Lowercase, remove punctuation, filter stopwords, and lemmatize.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    normalized_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(normalized_tokens)\n",
    "\n",
    "# Download transcription JSON from S3\n",
    "def download_json_from_s3():\n",
    "    try:\n",
    "        json_buffer = io.BytesIO()\n",
    "        s3_client.download_fileobj(bucket_name, json_key, json_buffer)\n",
    "        json_buffer.seek(0)\n",
    "        print(f\"✅ Transcription JSON is downloaded from s3://{bucket_name}/{json_key}\")\n",
    "        return json_buffer\n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Download error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Save normalized result locally\n",
    "def save_normalized_json_to_local(normalized_data):\n",
    "    try:\n",
    "        path = '/tmp/normalized_transcripts.json'\n",
    "        with open(path, 'w') as file:\n",
    "            json.dump(normalized_data, file, indent=4)\n",
    "        print(f\"📄 Normalized transcription JSON is saved locally at {path}\")\n",
    "        return path\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Local save error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Upload normalized JSON to S3\n",
    "def upload_json_to_s3(local_path):\n",
    "    try:\n",
    "        s3_client.upload_file(local_path, bucket_name, normalized_json_key)\n",
    "        print(f\"✅ Normalized transcription JSON is uploaded to s3://{bucket_name}/{normalized_json_key}\")\n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Upload error: {e}\")\n",
    "\n",
    "# Main process\n",
    "def process_transcriptions():\n",
    "    json_buffer = download_json_from_s3()\n",
    "    if not json_buffer:\n",
    "        return\n",
    "\n",
    "    transcriptions = json.load(json_buffer)\n",
    "    normalized_transcriptions = {\n",
    "        key: normalize_text_nltk(value) for key, value in transcriptions.items()\n",
    "    }\n",
    "\n",
    "    local_path = save_normalized_json_to_local(normalized_transcriptions)\n",
    "    if local_path:\n",
    "        upload_json_to_s3(local_path)\n",
    "\n",
    "# Run normalization\n",
    "process_transcriptions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting key phrases and topics\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to extract the key phrases and topics from the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted key phrases and topics JSON are uploaded to s3://nlpprojectamirhossein/json/extracted_key_phrases_and_topics.json successfully.\n"
     ]
    }
   ],
   "source": [
    "# ------------------- SETUP -------------------\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'nlpprojectamirhossein'\n",
    "\n",
    "# Input and output keys\n",
    "raw_json_key = 'json/transcriptions.json'\n",
    "normalized_json_key = 'json/normalized_transcripts.json'\n",
    "output_key = 'json/extracted_key_phrases_and_topics.json'\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(\n",
    "    filename='project.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# ------------------- TEXT PROCESSING -------------------\n",
    "\n",
    "def normalize_text_for_rake(text):\n",
    "    \"\"\"Lightly clean text and chunk it to simulate sentence-like structure for RAKE.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s\\.\\,\\?\\!]', '', text)\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + 20]) + '.' for i in range(0, len(words), 20)]\n",
    "    return ' '.join(chunks)\n",
    "\n",
    "# ------------------- NLP FUNCTIONS -------------------\n",
    "def extract_key_phrases(text, top_n=5, min_score=11, min_words=2):\n",
    "    try:\n",
    "        rake = Rake()\n",
    "        rake.extract_keywords_from_text(text)\n",
    "        phrases_with_scores = rake.get_ranked_phrases_with_scores()\n",
    "\n",
    "        seen = set()\n",
    "        filtered_phrases = []\n",
    "\n",
    "        for score, phrase in phrases_with_scores:\n",
    "            phrase = phrase.strip()\n",
    "            if phrase in seen:\n",
    "                continue\n",
    "            if score < min_score or len(phrase.split()) < min_words:\n",
    "                continue\n",
    "            seen.add(phrase)\n",
    "            filtered_phrases.append({\n",
    "                \"text\": phrase,\n",
    "                \"score\": round(score, 2)\n",
    "            })\n",
    "            if len(filtered_phrases) == top_n:\n",
    "                break\n",
    "\n",
    "        return filtered_phrases\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting key phrases: {e}\")\n",
    "        return []\n",
    "\n",
    "# Define a set of filler/noise words to exclude from topics\n",
    "FILLER_WORDS = {\n",
    "    \"youll\", \"section\", \"module\", \"topic\", \"video\", \"lesson\", \"introduction\",\n",
    "    \"overview\", \"slide\", \"course\", \"content\", \"example\", \"use\", \"identify\", \"set\", \"well\", \"one\", \n",
    "}\n",
    "\n",
    "def identify_topics(text, num_topics=3):\n",
    "    \"\"\"Identify topics from normalized text using LDA.\"\"\"\n",
    "    try:\n",
    "        words = text.split()\n",
    "        if len(words) < 5:\n",
    "            logging.warning(\"Text too short for LDA topic modeling.\")\n",
    "            return []\n",
    "        dictionary = corpora.Dictionary([words])\n",
    "        corpus = [dictionary.doc2bow(words)]\n",
    "        lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "        \n",
    "        # Get the top topic by weight\n",
    "        topic_distribution = lda_model.get_document_topics(corpus[0])\n",
    "        top_topic_id = max(topic_distribution, key=lambda x: x[1])[0]\n",
    "\n",
    "        # Return only the top topic\n",
    "        return [lda_model.show_topic(topicid=top_topic_id, topn=5)]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting topics: {e}\")\n",
    "        return []\n",
    "\n",
    "def clean_lda_topics(lda_output):\n",
    "    \"\"\"Clean and normalize the most relevant LDA topic into one list.\"\"\"\n",
    "    if not lda_output:\n",
    "        return []\n",
    "\n",
    "    topic = lda_output[0]  # only one topic\n",
    "    words = [\n",
    "        re.sub(r'[^a-z]', '', item[0].strip().lower())  # Clean word\n",
    "        for item in topic\n",
    "    ]\n",
    "    \n",
    "    # Filter out filler/noise words\n",
    "    words = [w for w in words if len(w) > 2 and w not in FILLER_WORDS]\n",
    "\n",
    "    # Deduplicate and sort for consistency\n",
    "    return [sorted(set(words))] if words else []\n",
    "\n",
    "# ------------------- S3 HELPERS -------------------\n",
    "\n",
    "def check_file_exists(bucket, key):\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket, Key=key)\n",
    "        return True\n",
    "    except s3_client.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False\n",
    "        logging.error(f\"Error checking {key}: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_file_from_s3(bucket, key, local_filename):\n",
    "    if not check_file_exists(bucket, key):\n",
    "        raise FileNotFoundError(f\"{key} not found in {bucket}\")\n",
    "    try:\n",
    "        s3_client.download_file(bucket, key, local_filename)\n",
    "        logging.info(f\"Downloaded {key}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading {key}: {e}\")\n",
    "        raise\n",
    "\n",
    "# ------------------- PROCESSING FUNCTION -------------------\n",
    "\n",
    "def process_transcription(key, raw_text, normalized_text):\n",
    "    try:\n",
    "        key_phrases = extract_key_phrases(normalize_text_for_rake(raw_text))\n",
    "        raw_topics = identify_topics(normalized_text)\n",
    "        topics = clean_lda_topics(raw_topics)\n",
    "        return key, {\n",
    "            \"key_phrases\": key_phrases,\n",
    "            \"topics\": topics\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {key}: {e}\")\n",
    "        return key, {\n",
    "            \"key_phrases\": [],\n",
    "            \"topics\": []\n",
    "        }\n",
    "\n",
    "# ------------------- MAIN SCRIPT -------------------\n",
    "\n",
    "# Step 1: Download files from S3\n",
    "download_file_from_s3(bucket_name, raw_json_key, 'raw_transcriptions.json')\n",
    "download_file_from_s3(bucket_name, normalized_json_key, 'normalized_transcriptions.json')\n",
    "\n",
    "# Step 2: Load JSON contents\n",
    "with open('raw_transcriptions.json', 'r') as f:\n",
    "    raw_transcriptions = json.load(f)\n",
    "\n",
    "with open('normalized_transcriptions.json', 'r') as f:\n",
    "    normalized_transcriptions = json.load(f)\n",
    "\n",
    "# Step 3: Process each transcript in parallel\n",
    "results = {}\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {\n",
    "        executor.submit(\n",
    "            process_transcription,\n",
    "            key,\n",
    "            raw_transcriptions[key],\n",
    "            normalized_transcriptions[key]\n",
    "        ): key\n",
    "        for key in raw_transcriptions if key in normalized_transcriptions\n",
    "    }\n",
    "    for future in futures:\n",
    "        try:\n",
    "            key, result = future.result()\n",
    "            results[key] = result\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to process key {futures[future]}: {e}\")\n",
    "\n",
    "# Step 4: Save processed data locally\n",
    "with open('extracted_key_phrases_and_topics.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Step 5: Upload results to S3\n",
    "try:\n",
    "    s3_client.upload_file('extracted_key_phrases_and_topics.json', bucket_name, output_key)\n",
    "    print(f\"✅ Extracted key phrases and topics JSON are uploaded to s3://{bucket_name}/{output_key} successfully.\")\n",
    "    logging.info(f\"Uploaded to s3://{bucket_name}/{output_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Upload failed: {e}\")\n",
    "    logging.error(f\"Upload failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the dashboard\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to create the dashboard for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h5>⚠️ Flask Dashboard should be run first in EC2, Then you can open dashboard by clicking on below link </h5>\n",
       "<a href=\"http://54.162.24.54:5000/\" target=\"_blank\" style=\"font-size: 16px; color: blue;\">Click here to open the dashboard</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------- Flask Dashboard Deployed on EC2 (Ubuntu) -------------------\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "url = \"http://54.162.24.54:5000/\"\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<h5>⚠️ Flask Dashboard should be run first in EC2, Then you can open dashboard by clicking on below link </h5>\n",
    "<a href=\"{url}\" target=\"_blank\" style=\"font-size: 16px; color: blue;\">Click here to open the dashboard</a>\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
