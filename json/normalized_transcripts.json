{
    "Mod01_Course Overview": "hi welcome amazon academy machine learning foundation module youll learn course objective various job role machine learning domain go learn machine learning completing module able identify course prerequisite objective indicate role data scientist business identify resource learning going look prerequisite taking course take course recommend first complete aws academy cloud foundation also general technical knowledge including foundational computer literacy skill like basic computer concept email file management good understanding internet also recommend intermediate skill python programming general knowledge applied statistic finally general business knowledge important course includes insight information technology used business also important businessrelated skill set communication skill leadership skill orientation towards customer service course youll introduced key concept machine learning tool us youll also introduced work aws service machine learning youll learn recognize machine learning deep learning part artificial intelligence describe artificial intelligence machine learning terminology identify machine learning used solve business problem describe machine learning process list tool available data scientist identify use machine learning instead traditional software development method part course youll also learn implement machine learning pipeline includes formulate problem business request obtain secure data machine learning build jupyter notebook using amazon sagemaker outline process evaluating data explain data need preprocessed use open source tool examine preprocess data also use amazon sagemaker train host machine learning model use cross validation test performance machine learning model use hosted model inference create amazon sagemaker hyperparameter tuning job optimize model effectiveness finally use managed amazon machine learning service solve specific machine learning problem forecasting computer vision natural language processing well review course outline achieve course objective youll complete following module start module youll get introduction machine learning module youll learn implement machine learning pipeline amazon sagemaker module describe apply managed amazon machine learning service problem forecasting computer vision natural language processing finally module summary course also includes overview step take work towards aws certified machine learning specialty next five slide provide detail subtopics covered module purpose module introduce major concept understanding machine learning section describes overall field machine learning machine learning relates artificial intelligence deep learning section youll learn common business problem solve machine learning section describes general workflow solving machine learning problem youll also learn common machine learning term section youll review commonly used tool machine learning professional lastly section youll get overview common challenge youll face working machine learning problem module youll get introduction amazon sagemaker use implement machine learning pipeline module focus application machine learning solve problem several public domain data set example machine learning pipeline section introduces defining business problem data set well use module section describes phase machine learning pipeline using computer vision example application section youll learn collect secure data section describes different technique evaluating data section youll learn process feature engineering section describes step youll take train model sagemaker section youll get overview option sagemaker hosting using model finally section cover evaluate tune model sagemaker module youll introduced using machine learning create forecast based time series data section youll introduced forecasting common application section outline pitfall using time series data make forecast finally section youll get overview use amazon forecast module youll learn using machine learning computer vision section describes general problem solve computer vision section youll learn process analyzing image video section youll learn step youll need take prepare data set computer vision module youll introduced natural language processing machine learning section youll learn general set problem solve natural language processing section review managed amazon machine learning service use address natural language processing problem service include amazon transcribe amazon translate amazon lex amazon comprehend amazon poly module final module course module youll review youve learned throughout course youll also introduced next step take want achieve aws certified machine learning specialty section module summarizes topic youve covered course section youll learn aws documentation youll also review two common framework applying aws service finally section describes step take want continue working towards aws certified machine learning specialty section youll learn common job role machine learning professional youre interested data scientist role focus developing analytical statistical programming skill data scientist youll use skill collect analyze interpret large data set university offer degree data science data scientist often degree related field like statistic math computer science economics data scientist youll need technical competency statistic machine learning programming language data analytics youd like career machine learning engineer skill youll need similar data scientist skill set like data scientist machine learning engineer also require technical competency statistic machine learning however youll focus programming skill software architecture analysis interpretation machine learning engineer youll apply programming architecture skill design develop machine learning system machine learning engineer often previous experience software development rely heavily programming software engineering machine learning role might also interested career science apply machine learning technology field machine learning impact everything astronomy zoology many different path open applied science researcher primary focus type science youre working youll need skill data scientist youll also need know apply skill chosen domain thus applied science role also require technical competency statistic machine learning many software developer integrating machine learning application youre interested career software developer also include machine learning technology study machine learning developer primary focus software development skill youll also need skill data scientist make sure take coursework statistic applied mathematics here final note module recommend reviewing student guide student guide youll find link documentation resource youll use throughout course thats introduction thanks watching well see next video",
    "Mod02_Intro": "hi welcome module aws academy machine learning module going introduce machine learning well first look business problem solved machine learning well talk terminology process tool challenge youll face completing module able recognize machine learning deep learning part artificial intelligence describe artificial intelligence machine learning terminology identify machine learning used solve business problem describe machine learning process list tool available data scientist identify use machine learning instead traditional software development method youre ready get started section see next video",
    "Mod02_Sect01": "hi welcome section section going talk machine learning course introduction machine learning also known ml first well discus machine learning fit larger picture machine learning subset artificial intelligence ai broad branch computer science thats focused building machine human task deep learning subdomain machine learning understand fit together well discus one mentioned machine learning subset broader computer science field known artificial intelligence ai focus building machine perform task human would typically perform contemporary popular culture youve probably seen ai movie television work fiction example might seen ai control world around start acting initiative ai started computer agent perceive environment take action achieve specific goal though maybe outcome created originally wishfloor fictional ai interact extensively human helper worker generally better job working humanity theyre general purpose kind ai example artificial general intelligence agi capacity learn understand task human ai problem typically span many field research natural language processing reasoning knowledge representation learning perception physical environment interaction ai isnt yet reality u unless truly living simulation every year move closer area might also read seen commentary ethic creating ai view positive perhaps partly fear malicious fictional ai want destroy humanity use power source perhaps theyre concerned risk mass unemployment intelligent machine could work need break dont worry though going build next rogue ai course maybe next one search youll probably find many definition machine learning isnt universally agreed upon definition well start looking couple definition example could say machine learning scientific study algorithm statistical model perform task using inference instead instruction isnt bad starting point key point using algorithm statistical model instead instruction help better understand well apply idea concrete example suppose need write application determines email message spam without machine learning youd need write complex series decision statement using else statement youd also need use word subject body number link length message determine email message spam would hard labor intensive build large set rule covering every possibility machine learning however could use list email message marked spam spam train machine learning model model would learn pattern word length attribute good indicator spam message presented model email message hadnt seen model would perform prediction say whether message spam spam artificial learning represents significant leap forward capability artificial intelligence machine learning theory behind deep learning created human brain work artificial neural network ann inspired biological neuron found brain although implementation become different artificial neuron one input single output neuron fire activate output based transformation input neural network composed layer artificial neuron connection layer typically input output hidden layer network output single neuron connects input neuron next layer network asked solve problem input layer populated training data neuron activate throughout layer answer presented output layer accuracy output measured output doesnt meet threshold training repeated slight change weight connection neuron neural network repeatedly time strengthens connection lead success diminishes connection lead failure youll see course machine learning practitioner spend lot time optimizing ml model selecting best data feature train selecting model best result contrast deep learning practitioner spend almost time task instead spend time modeling data different ann architecture though theory deep learning go back decade hardware needed run deep learning problem wasnt generally accessible recently available use deep learning address problem complex problem could worked mainstream machine learning recent occurrence rapid advancement machine deep learning started around mids partly moore law rise cloud computing resulted easier access larger faster cheaper compute storage capability rent computing power hour penny needed substantial investment buy operate largescale compute cluster neural network started used imagenet largescale visual recognition challenge machine learning competition image recognition accuracy rate jumped percent steadily climbing ever since fact exceeded human performance key takeaway section first artificial intelligence broad field building machine perform human task also machine learning subset ai focus using data train machine learning model make prediction deep learning technique inspired human biology us layer artificial neuron build network solve problem last advancement technology cloud computing algorithm development led corresponding advance machine learning capability application thats section well see next video",
    "Mod02_Sect02": "hi welcome back section going look type business problem machine learning help solve machine learning used across digital life email spam filter result machine learning program trained example spam regular email message based book youre reading product bought machine learning program predict book product youre likely interested machine learning program trained data reader habit purchase detecting credit card fraud machine learning program trained example transaction turned fraud along normal transaction probably think many example social medium application using facial detection group photo detecting brain tumor brain scan finding anomaly xrays three main type machine learning there supervised learning model us known input output generalize future output there unsupervised learning model doesnt know input output find pattern data without help there reinforcement learning model interacts environment learns take action maximize reward important know different type ml type guide towards selecting algorithm make sense solving business problem let look type supervised learning popular type ml widely applicable called supervised learning need supervisor teacher show right answer speak like student supervised algorithm need learn example essentially need teacher us training data help determine pattern relationship input output want build application detect credit card fraud youd need training data includes example fraud example normal transaction within supervised learning different type problem classification regression two subtypes classification problem first binary classification think back example identifying fraudulent transaction target variable example limited two option fraudulent fraudulent binary classification problem also multiclass classification problem ml problem classify observation one three category say ml model predicts customer calling store reduce number transfer needed customer get correct customer support department case different customer support department represent variety potential target variable could many different department much two also regression problem regression problem youre longer mapping input defined number category instead youre mapping input continuous value like integer one example ml regression problem predicting price company stock computer vision good example supervised learning cat dog tumor xray computer vision often built deep learning model automates extraction analysis classification understanding useful information single image sequence image computer vision enables machine identify people place thing image accuracy human level greater speed efficiency image data take many form single image video sequence view multiple camera threedimensional data youll learn computer vision later course well discus unsupervised machine learning sometimes data there supervisor room unsupervised learning label arent provided like supervised learning dont know variable pattern instance machine uncover create label model use data theyre presented detect emerging property entire data set construct pattern property clustering common subcategory unsupervised learning kind algorithm group data different cluster based similar feature better understand attribute specific cluster example analyzing customer purchasing habit unsupervised algorithm identify group customer associated size tier company advantage unsupervised algorithm enable see pattern data werent aware visual language processing also known nlp another area machine learning thats experiencing growth youve ever used alexa voice assistant theyll use nlp try answer question nlp isnt speech also written text nlp show many application example nlp used chat call center bot automated system help get bank balance order food restaurant use nlp translation tool convert text language example might use application translate menu real time nlp also used voice text translation convert spoken word text finally nlp used sentiment analysis use analyze sentiment comment review product music movie sentiment could used give movie audience rating youll learn nlp later course another kind machine learning thats gaining popularity recently reinforcement learning unlike machine learning reinforcement learning continuously improves model mining feedback previous iteration reinforcement learning agent continuously learns trial error interacts environment reinforcement learning broadly useful reward desired outcome known path achieving isnt path requires lot trial error discover take example aws deepracer aws deepracer simulator agent virtual car environment virtual racetrack action throttle steering input car goal completing racetrack quickly possible without deviating track car need learn desired driving behavior reach goal completing track car learn aws deepracer team use reward incentivize model learn desired driving behavior reinforcement learning thing driving learning called agent case aws deepracer car environment place agent learns example would marked racetrack agent something environment provokes response crossing boundary shouldnt cross thats called action response called reward penalty depending whether agent something reinforced discouraged model agent move within environment action start receiving reward fewer penalty meet desired business outcome selfdriving vehicle bring together many machine deep learning algorithm model solve problem driving point point b two main task continuous detection environment forecasting change involve detecting object localizing predicting movement detected object output finding act input system make decision vehicle various control use case selfdriving vehicle require realtime response environment example previously hidden pedestrian walk behind obstacle vehicle brake need applied immediately latency room error action every problem solved machine learning sometimes regular programming work well need youre interested exploring potential machine learning solution look existence large data set large number variable machine learning often best choice youre uncertain business logic procedure needed obtain answer accomplish task machine learning system complex supporting infrastructure management support technical expertise need place help ensure project success key takeaway section explored machine learning application already part everyday life first machine learning problem grouped three category supervised learning training data already know answer unsupervised learning data looking insight within data reinforcement learning model learns based experience feedback business problem supervised learning problem let section well see next video",
    "Mod02_Sect03": "hi welcome back section going give quick highlevel overview machine learning terminology typical workflow cover topic detail later course well focus larger picture begin always start business problem team believe could benefit machine learning want problem formulation phase one task articulate business problem convert ml problem youve formulated problem move data preparation preprocessing phase youll pull data one data source data source might difference data type need reconciled form single cohesive view data youll need visualize data use statistic determine data consistent used machine learning well look data source later course example data four column containing data three different data source source slightly different way representing data result shown table ml problem column represent feature row represent instance issue data instance case youll need subject matter expert functional expert understand authenticity data example date thats represented could november nd february th year someone owns manages data pool would able clarify ambiguity also word male probably attributed import issue cell shifted position could outside chance actual location male city thats capital republic maldives time error identification isnt simple youll need sme review data youll learn role expert later course remember one largest impact success machine learning project consistent correct data data good shape time train model process get iterative fluid youll likely go many multiple pass feature engineering training evaluating tuning find model meet business goal feature engineering process selecting creating feature model trained feature column data data set goal model correctly estimate target value new data ml algorithm use feature predict target example target data average number step taken week selecting correct feature involve adding removing calculating new feature might want make data format consistent consistent format could later used model make change cosmetic reason depending problem want solve data might even need include name feature example data country feature traditional database might want move country lookup table reference ml algorithm want data instance single row ml algorithm need numerical data process could consider turning country text country iso code however model might interpret numerical value meaning uk iso code value would significant iso code value u case splitting data multiple column fine known categorical encoding youll learn later course type data could convert text value numerical value example could use represent male female numeric value used easily model remaining feature like age birth month shown bm table day week shown dow extracting age birth month day week might appropriate depending problem youre trying solve age impact target variable day week born dont worry sound complicated youll learn feature engineering later course data cleaned youve identified feature want use time train model wont use data train model fact need hold data data test typically youll use data train youll save rest data testing next youll train model training data diagram model us xg boost algorithm model parameter set parameter alter algorithm work theyre known hyperparameters output training job trained model trained model use test data see well model performs youll take instance model hasnt seen use perform prediction already know target test data compare two value comparison calculate metric give data well model performing youll make change model data feature hyperparameters find model yield best result training model there real danger overfitting underfitting model model overfitting training data see model performs well training data doesnt perform well evaluation data model memorizing data saw cant generalize unseen example model underfitting training data model performs poorly training data model cant capture relationship input example often called x target value often called understanding model fit important understanding root cause poor model accuracy understanding guide take corrective step determine whether predictive model underfitting overfitting training data looking prediction error training data evaluation data well show step take avoid later course youve retrained model youre satisfied result deploy model deliver best possible prediction later course well walk different phase give handson experience knowing process also useful using managed service well also explore later certain amazon ml service bulk work key takeaway section first looked machine learning pipeline process guide process training evaluating model iterative process broken three broad step data processing model training model evaluation thats video well see next one",
    "Mod02_Sect04": "welcome back section well look tool youll using throughout rest course start list isnt exhaustive list tool available today going cover high level good place get started first there jupyter notebook jupyter notebook open source web application use create share document contain live code equation visualization narrative text us include data cleaning transformation numerical simulation statistical modeling data visualization machine learning much jupyter lab webbased interactive development environment jupyter notebook code data jupyter lab flexible use configure arrange user interface support wide range workflow data science scientific computing machine learning jupyter lab extensible modular write plugins add new component integrate existing one later course youll use amazon sagemaker host jupyter notebook jupyter lab panda open source python library used data handling analysis panda represents data table similar spreadsheet table known panda dataframe matplotlib python library creating scientific static animated interactive visualization python youll use generate plot data later course seaborn another data visualization library python thats built matplotlib provides highlevel interface drawing attractive informative statistical graph numpy one fundamental scientific computing package python contains function ndimensional array object also useful math function linear algebra fourier transform random number capability syphitlearn open source machine learning library support supervised unsupervised learning also provides various tool model fitting data preprocessing model selection evaluation many utility syphitlearn built numpy sypy matplotlib good tool exploring machine learning although youll use borrow function course might want consider exploring complete course moving individual library package also tool contain production ready framework already mentioned syphitlearn good library machine learning framework supported aws tensorflow kera also include library use machine learning framework listed supported aws used amazon sagemaker aws also provides compute instance tuned machine learning cloud edge compute instance optimized learning inference another aws resource use certain amazon machine image amis offer prepackaged amis contain many popular framework finally there amazon sagemaker aws service many capability first sagemaker deploy machine learning instance running jupyter notebook jupyter lab manages deployment compute resource need connect jupyter environment sagemaker also provides tool labeling data training model hosting trained model aws marketplace also provides selection readytouse model package algorithm thirdparty machine learning developer aws also provides set managed machine learning service integrate application even dont substantial machine learning experience computer vision amazon recognition provides object facial recognition image video also amazon textract extract text image speech service include amazon poly speak text another speech service amazon transcribe convert spoken audio text language amazon comprehend us nlp find insight relationship text also amazon translate translate text different language want work chatbots amazon lex help build interactive conversational application use voice text forecasting amazon forecast us machine learning combine time series data additional variable build forecast finally youd like work recommendation amazon personalize help create individual personalized recommendation customer managed service already trained many aspect problem domain need provide specific data get started going look many managed service second half course learn thing key takeaway section include point first python popular language performing machine learning task jupiter notebook provide webbased hosted development environment machine learning youll use jupiter notebook frequently machine learning large number opensource tool panda youll use often machine learning practitioner finally depending upon requirement might start lowlevel framework create solution might also use tool amazon sagemaker help heavy lifting simply use adapt one managed amazon ml service specific problem domain thats video well see next one",
    "Mod02_Sect05": "hi welcome back section going discus challenge machine learning youll come across many challenge machine learning lot poor quality inconsistent data available significant portion job getting access generating enough good data thats representative problem want solve key issue watch overfitting model data although mostly data science experience staffing team data scientist cost effective management support using machine learning business landscape look like problem complex formulate machine learning problem resulting model explained business cant explained might get adopted whats cost building updating operating machine learning solution finally technology map business unit access data thats needed data secured meet regulatory requirement tool framework used solution integrate system important question successful youll need able answer address many machine learning problem solved today using existing model without substantial machine learning knowledge weve already talked aws managed service machine learning add sophisticated machine learning capability application basic developer skill calling apis prebuilt model use adapt one example yolo mean look yolo popular computer vision model addition scenario use aws marketplace youd prefer buy model service independent software vendor instead developing key takeaway section first youll face many machine learning challenge biggest one directly influence related data consider managed service solve machine learning problem within domain support using amazon recognition computer vision problem thats section well see next video",
    "Mod02_WrapUp": "time review module main takeaway module first looked defining machine learning fit broader ai landscape also looked type problem machine learning help u solve machine learning applies learning algorithm develop model large data set looked machine learning pipeline different stage developing machine learning application finally introduced tool service use discussing challenge machine learning summary module learned recognize machine learning deep learning part artificial intelligence describe artificial intelligence machine learning terminology denify machine learning used solve business problem describe machine learning process list tool available data scientist identify use machine learning instead traditional software development method thanks watching well see next video",
    "Mod03_Intro": "welcome back aws academy machine learning module going work entire machine learning pipeline using amazon sagemaker module discus typical process handling machine learning problem machine learning pipeline applied many machine learning problem focus supervised learning process learn module adapted type machine learning well large module well covering lot material end module youll able formulate problem business request obtain secure data machine learning jupiter notebook using amazon sagemaker outline process evaluating data explain data need preprocessed use open source tool examine preprocess data use amazon sagemaker train host machine learning model use cross validation test performance machine learning model use hosted model inference finally create amazon sagemaker hyperparameter tuning job optimize model effectiveness ready get started see next video",
    "Mod03_Sect01": "hi welcome back module section going take look data set well use module well also look guidance formulate business problem get started here reminder machine learning pipeline looked previous module map section module section section cover formulate problem also cover data set well use throughout module section discus obtain secure data machine learning activity section well show tool technique gaining understanding data section well look preprocessing data ready train model section cover selecting training appropriate machine learning model section show deploy model make prediction section examine process evaluating performance machine learning model finally section well look tuning model machine learning pipeline iterative process work realworld problem might find iterating many time arrive solution meet business need first section well examine think turning business requirement machine learning problem first step phase simply define problem want solve goal want reach understanding business goal key youll use measure performance solution unusual solidify business problem begin targeting solution lot question ask develop good understanding problem information problem begin framing approach first problem even solved machine learning would traditional approach make sense supervised unsupervised machine learning problem labeled data train supervised model many question could ask business ultimately try validate use machine learning make sure access right people data also try come simplest solution problem here example want identify fraudulent credit card transaction stop transaction process thats problem whats business goal outcome driving problem statement case say intended outcome reduction number customer end membership credit card result fraudulent transaction business perspective define success given problem desired outcome stage need move qualitative statement quantitative statement easily measured depending example metric could use define success problem might reduction number customer file claim fraudulent transaction within six month period youve defined business side problem time start thinking term machine learning model whats actual output want see model want specific statement reflects ml model could actually output example might model output whether credit card transaction fraudulent fraudulent know want ml model actually achieve use information determine type ml youre working historical data customer file report fraud transaction use data machine learning purpose historical data fall supervised learning approach label already defined recall earlier course supervised ml type categorized two group classification regression credit card example desired output categorizing transaction fraud fraud see youre dealing binary classification problem throughout module youll see several data set used access data set many uc irvine machine learning repository first data set contains numerical information composition wine along quality wine question might want ask data set based composition wine could predict quality therefore price addition question well also use data set view statistic deal outlier scale numerical data second data set car evaluation database data set heavily text based enables explore encoding categorical data convert text value number processed machine learning third data set biomedical data set youll also use lab question answer data set based biomechanical feature predict patient abnormality data set take entire endtoend process youll end trained model thats tuned use make prediction section looked business problem need converted ml problem also looked key question ask defining success measure outcome impact solution implemented business problem fall one two category first category classification binary multiclass ask target belong class second category regression ask predict numerical value thats section one well see next video",
    "Mod03_Sect02_part1": "hi welcome back going look way collect secure data section well explore technique challenge associated collecting securing data thats needed machine learning consider original example predicting credit card fraud youve formulated problem data need actually train model get desired output subsequently achieve intended business outcome access data much data solution use bring data one centralized repository answer question essential stage good news budding data scientist many place obtain data private data existing customer already exists including everything log file customer invoice database private data useful depending problem youre trying solve many case private data found many different system well look bring source together shortly sometimes want use data collected made available commercial organization reuters change healthcare dunn bradstreet forsquare maintain database subscribe include curated news story anonymized healthcare transaction global business record location data supplement data commercial data get useful insight wouldnt gotten otherwise also many open source data set ranging wine quality movie review data set made available use research teaching purpose aws kaggle uci machine learning repository good place find open source data set government health organization source data could useful machine learning problem need lot data also called observation already need know target answer prediction data kind data already know target answer prediction called labeled data observation data made two element target feature target answer want predict credit card transaction example target given observation either fraud fraud feature attribute example use identify pattern predicting target answer feature credit card example could date transaction vendor amount dollar transaction might wonder source target fraud fraud typically information discovered transaction complete actual card owner notice fraudulent transaction statement information would recorded transaction exactly purpose using train future model given know element ml data set well return one original question data need actually train model reach desired output subsequently intended business outcome example stage ml pipeline crucial get domain expertise help answer question domain knowledge start determining feature target data model need make accurate prediction data representative data youll youre using model make prediction example want predict credit card fraud need collect data positive fraudulent transaction also need collect data negative nonfrogulent transaction need type data machine learning algorithm find pattern distinguish two type suppose average amount fraudulent transaction actually training data set includes small fraction fraudulent observation say case itll difficult model truly learn pattern related fraudulent transaction might encounter production many different service aws could find store data key service might use amazon simple storage service also known amazon provides object level storage store much data want form object think file could csv file file format need accessed webbased aws management console also access programmatically api sdks thirdparty solution also use api sdks training data already youre planning run training job several time different algorithm parameter could use amazon fsx luster file system service speed training job serving data amazon sagemaker high speed first time run training job fsx luster automatically copy data make available sagemaker use amazon fsx file system subsequent iteration training job prevents repeated downloads common object alternatively training data might already amazon elastic file system amazon efs recommend using efs data source training data launch training job directly service without needing data movement result faster training start time often case environment data scientist home directory amazon efs quickly iterate model bringing new data sharing data colleague experimenting different field label data set example data scientist use jupyter notebook initial cleansing training set launch training job amazon sagemaker could use jupyter notebook drop column relaunch training job finally compare resulting model see one work better many aws service resource might find data example could use amazon relational database service amazon rds manage relational database service could also use amazon redshift manage data warehouse service another option amazon timestream manage time series database designed specifically handle large amount data internet thing iot could even spin instance amazon elastic compute cloud also known amazon ec post database instance data source youll need extract useful data source assembling data machine learning well look next thats part one section well see part two well review extract transform load data",
    "Mod03_Sect02_part2": "hi welcome back well continue exploring data collection reviewing extract transform load data data typically spread across many different system data provider present challenge youll need bring data source together something consumed machine learning model extract transform load also known etl step etl defined way extract step pull data source single location extraction might need modify data combine matching record task transform data finally load step data loaded repository amazon typical etl framework several component example consider diagram first crawler program connects data store source target progress ranked list classifier determine schema data creates metadata table aws glue data catalog job defines business logic thats needed perform etl work run job youll need use schedule event final note service discussed exist transform partition etl process aws glue fully managed etl service make simple costeffective categorize data clean enrich move reliably various data store aws glue consists central metadata repository known aws glue data catalog etl engine automatically generates python scala code also provides flexible scheduler handle dependency resolution job monitoring retries aws glue serverless dont need set manage infrastructure use aws glue console discover data transform make available searching query console call underlying service orchestrate work needed transform data also use aws glue api operation interface aws glue service way edit debug test python scala apache spark etl code using familiar development environment aws glue well suited machine learning receive label data used training here example say provide aws glue training data teach model duplicate record data source look like aws glue identify duplicate present analysis data engineer aws glue enables orchestration complex etl job example aws glue crawl data source present information client data catalog aws glue run etl job based event getting new data set example use aws lambda function trigger etl job run soon new data becomes available amazon also register new data set aws glue data catalog part etl job although managed tool available aws manipulate data data scientist also write script jupyter notebook handle data simple extract load script shown import variable section import library used note boto library aws variable also set zip file web location local folder extraction download extract section make web request saving byte url stream stream passed zip file function used extract data extracted file folder upload section enumerates folder file uploads file amazon discover script used often migrated standalone function imported python application thats part two section well see part three well review secure data",
    "Mod03_Sect02_part3": "hi welcome back well continue exploring data collection reviewing secure data important consider security data though data set used course public real data customer transaction health record need kept secure use aws identity access management also known iam service control access resource make sure youre securing data within aws correctly avoid data breach diagram show simple iam policy allows read access specific bucket listed role addition controlling access data need make sure data secure good practice might also legally required certain data type financial data health care record aws provides encryption feature storage service typically data thats rest transit often meet encryption requirement enabling encryption object service want protect data transit must use secure transport like secure socket layer transport layer security ssl tl another aspect consider compliance audit dealing data regulated industry youll often need audit access data aws cloudtrail service enables governance compliance operational auditing risk auditing aws account cloudtrail log continuously monitor retain account activity related action across entire aws infrastructure cloudtrail provides event history aws account activity including action taken aws management console aws sdks command line tool aws service event history simplifies security analysis resource change tracking troubleshooting also use cloudtrail detect unusual activity aws account feature help simplify operational analysis troubleshooting key takeaway section looked first step solving machine learning problem obtaining data required train machine learning model also reviewed etl used obtain data multiple source service like aws glue make easy obtain data multiple data store finally make sure understand security requirement based business need regulatory requirement also make sure data secure authorized user able access data encrypted possible thats section two well see next video",
    "Mod03_Sect03_part1": "hi welcome back section going cover evaluate data section well look different data format type well also look visualize analyze data feature engineering start running statistic data better understand youre working need ensure right format analysis amazon sagemaker algorithm support training data csv format many tool youll use explore visualize analyze data also read csv format generally speaking youll need least domain knowledge problem youre trying solve machine learning example youre developing model predict set symptom indicates disease youd need know relationship symptom disease data typically need numeric form machine learning algorithm use data make prediction well look way convert text data next section well explore data try gain insight overall data set one popular open source python library panda take data various format reformat load tabular representation data presenting row column format panda reformat load include csv excel pickle javascript object notation json panda also data analysis manipulation feature well use throughout module loading data simple example pull csv file specified url load data panda stored panda data frame panda documentation data frame described general labeled size mutable tabular structure potentially heterogeneously typed column helpful way think data frame think spreadsheet sql table like table spreadsheet data frame row also known instance column also known attribute shape property data frame describes number row column column data frame series series onedimensional labeled array series store data type learn data structure panda see panda documentation along data load data frame row label column label row label known index column label known column loaded data csv file header row column created first line file change behavior however dont column name source file pas parameter performing data analysis important make sure youre using correct data type many case panda correctly infer correct data type load data move domain knowledge access domain expert often identify data type issue use either type info function obtain information column type shown example dont correct data type need figure case often numeric column could missing data could single text value example car data set number door youve analyzed data convert column correct data type using panda thats part section well see part well review describe data",
    "Mod03_Sect03_part2": "hi welcome back well continue exploring describe data data readable format perform descriptive statistic data better understand descriptive statistic help gain valuable insight data effectively preprocess data prepare ml model look discus important first descriptive statistic organized different category overall statistic include number row number column data set information relates dimension data important example indicate many feature lead high dimensionality poor model performance attribute statistic another type descriptive statistic specifically numeric attribute theyre used get better sense shape attribute includes property like mean standard deviation variance minimum maximum value need look relationship one variable consider multivariate statistic mostly relate correlation relationship attribute case multiple variable feature might want look correlation important identify correlation attribute high correlation two attribute sometimes lead poor model performance feature closely correlated theyre used model predict response variable could problem example model loss might converge minimum state aware highly correlated feature data set mean median two different measure describing extent data clustered around value position mean useful method understanding data data symmetrical however data skewed contains outlier median tends provide better metric understanding data relates central tendency instance outlier large value mean skewed one way wouldnt serve accurate representation value truly centered median isnt affected outlier way well talk outlier soon available viewed numerical data using method describe also method calculate mean median others also view statistic single multiple column even group data specific value categorical attribute look frequency attribute value data set information give idea inside categorical variable diagram show car data set made several categorical value buying maint log boot safety class safety either low medium high describe function see three unique value low frequent looking class column appears top value four unacc stand unaccounted account value might suggest imbalance target variable thats also categorical type look class distribution see whether there class imbalance data set inbalance data mark disproportionate ratio class instance data set made credit card transaction tenth percent labeled fraud case algorithm might learn well enough predict example credit card fraud visualization could help gain insight data might aware otherwise histogram often good visualization technique seeing overall behavior particular feature histogram answer question like feature data normally distributed many peak data skewness particular feature using histogram data visualization value binned taller peak histogram indicate common value numerical feature use density plot box plot addition histogram get idea whats inside particular feature like histogram visualization help answer question like whats range data peak data outlier special feature using question help understand data better also help decide need specialized data preprocessing box plot method graphically depicting group numerical data quartile two numerical variable feature data set might want look relationship scatter plot good way identify special relationship among variable case left diagram sulfate alcohol two numerical variable suppose want show relationship variable use scatter plot help visualize plot scattered around correlation among might high data scattered however might find relatively positive relationship two variable scatter plot matrix help look relationship multiple different feature panda easily create scatter plot matrix based column want look example three column give pairwise scatter plot two column scatter plot might want identify special region particular subset data could fit example relationship alcohol sulfate quality could plot value good poor quality wine like example plotting give idea useful particular variable youre using classification problem thats part two section well see part three well review correlation takeaway section",
    "Mod03_Sect03_part3": "hi welcome back well review find correlation data set quantify linear relationship among variable youre seeing scatter plot correlation matrix good tool situation conveys strong weak linear relationship among numerical variable one go high one low minus one correlation one mean two numerical feature perfectly correlated like saying proportional x correlation two variable minus one like saying proportional minus x linear relationship quantified correlation correlation zero mean there linear relationship doesnt mean there relationship indication there linear relationship two variable however looking number isnt always straightforward often easier view number theyre represented color well look heat map highest number one dark green minus one dark brown color give positive negative direction also show strong correlation use seaborne heat map function show correlation matrix looking chart there correlation citric acid fixed acidity would expected line citric acid contributes acidity wine however isnt much correlation fixed acidity ph ph measurement strength acid present fixed acidity measure quantity particular data set doesnt appear correlation key takeaway section module include point first step get data format used easily panda popular python library working data descriptive statistic help gain insight data use visualization examine data set detail thats section well see next video",
    "Mod03_Sect04_part1": "hi welcome section section going look feature engineering feature engineering one impactful thing improve machine learning model well look two thing help make model successful first feature selection second feature extraction process creating feature feature selection select relevant feature discard rest apply feature selection prevent redundancy irrelevance existing feature also use limit number feature help prevent overfitting feature extraction build valuable information raw data reformatting combining transforming primary feature new one process continues yield new data set consumed model achieve goal diagram show feature extraction cover range activity dealing missing data converting text data numerical data although list isnt exhaustive give idea data handling thats needed get data useful state many task different job working data youll want make sure data correct format consistently represented correctly spelled among task example might combine data extract data multiple column could also remove column altogether specific machine learning youll need convert text column numerical value youll also need decide handle outlier potentially rescale data next well look common task section machine learning algorithm work best numerical data youll need make sure column data set contain numeric data converting encoding might need make several pass data sheet encode example might variability text value row contain medium med value categorical data order youll want encode text numerical value capture ordinal relationship say data showing maintenance cost might encode low medium high high youve made sure categorical data uniform use tool like skykit learn panda encode data categorical data doesnt order youll need break data multiple column help make sure dont introduce ordinal relationship data isnt example suppose assigned value first color red assigned next value say blue model could interpret blue important red blue higher numeric value encoding nonordinal data multiple column feature better way think new feature like checkbox consider example three feature generated value indicates instance feature like color thats section well see next video",
    "Mod03_Sect04_part2": "hi welcome back well continue exploring feature engineering reviewing clean data set addition converting string data numerical data youll need clean data set several potential problem area encoding string data make sure string consistent youll also need make sure variable use consistent scale example one variable describes number door car scale probably two eight another variable describes number car particular type sold state california scale probably thousand data item might also capture one variable single value instance suppose data set includes variable combine safety maintenance single variable safe high maintenance youll need train machine learning system variable also split single variable two separate variable might also encounter data set missing data variable data set include outlier youll cover technique dealing situation section might find data missing example column data set could missing data data collection error maybe data wasnt collected particular feature data collection process underway missing data make difficult accurately interpret relationship related feature target variable regardless data ended missed important deal issue unfortunately machine learning algorithm cant handle missing value automatically youll need use human intelligence update missing value data thats meaningful relevant problem python library data manipulation include function finding missing data decide drop impute missing value question answered part better understanding value came missing first place much data missing value represent within larger data set instance say missing value randomly spread throughout data set dont represent larger portion respective row column case imputation likely better option contrast say column row large percentage missing value case dropping entire row column would preferred imputation decide drop row missing data use builtin function example panda dropna function drop row missing data drop specific data value using subset alternative dropping missing value impute value missing value different way impute missing value categorical value missing value usually replaced mean median frequent value numerical continuous variable missing value usually replaced mean median impute single row missing data known univariate also multiple row known multivariate well look univariate example scikitlearn imputer function used impute missing value fairly small data set two missing value missing value imputed strategy mean first calculate mean mean youll impute mean value missing value data library include impute package provides complex way impute data example include k nearest neighbor soft impute multiple imputation chain equation others thats part two section well see part three well review work outlier data",
    "Mod03_Sect04_part3": "hi welcome back well continue exploring feature engineering describing work outlier might also need clean data based outlier exist outlier point data set lie abnormal distance value theyre always something want clean add richness data set also make harder make accurate prediction skew value away normal value related feature outlier might also indicate data point actually belongs another column think outlier falling two broad category first single variation single variable univariate outlier second variation two variable multivariate outlier one common way find univariate outlier box plot box plot show far data point mean variable box plot show data value within two quartile mean value outside range represented line extending box sometimes called whisker scatter plot effective way see multivariate outlier example diagram show amount sulfate alcohol collection line scatter plot quickly visualize whether multivariate outlier two variable origin outlier likely inform deal preprocessing phase pipeline possibly later feature engineering several different approach dealing outlier could delete outlier outlier based artificial error mean outlier isnt natural introduced failure like incorrectly entered data could also transform outlier taking natural log value turn reduces variation caused extreme outlier value would reduce outlier influence overall data set finally could use mean feature impute value replace outlier value would good approach outlier caused artificial error isnt exhaustive list describes common option many extracted feature youll need select appropriate feature training model three main feature selection method filter method use statistical method measure relevance feature correlation target variable rapper method measure useful subset feature training model feature measuring successful model filter faster cheaper wrapper method dont involve training model repeatedly rapper typically find best subset feature there risk overfitting compared using subset feature filter method embedded method algorithm specific might use combination filter wrapper filter method use proxy measure instead actual model performance theyre fast compute still capture useful feature set common measure first pearsons correlation coefficient measure statistical relationship association two continuous variable second linear discriminant analysis lda used find linear combination feature separate two class third analysis variance anova used analyze difference among group mean sample finally chisquare single number tell much difference exists observed count count youd expect absolutely relationship population filter usually less computationally intensive wrapper produce feature set isnt tuned specific type predictive model lack tuning mean feature set filter general one wrapper filter also usually lower prediction performance wrapper however filter feature set doesnt contain assumption prediction model useful exposing relationship feature many filter provide feature ranking instead explicit best feature subset cutoff point ranking chosen cross validation filter also used preprocessing step wrapper enables wrapper used larger problem rapper method use predictive model score feature subset new subset used train model tested holdout set score subset calculated counting number mistake made holdout set error rate model wrapper train new model subset theyre computationally intensive however usually provide best performing feature set particular type model problem first selection start feature add best model found backward selection start feature drop one time selects best model embedded method combine quality filter wrapper method theyre implemented algorithm builtin feature selection method popular example method lasso ridge regression builtin penalization function reduce overfitting key takeaway section module first feature engineering involves selecting best feature machine learning preprocessing give better data work better data typically provides better result two category preprocessing converting data numerical value cleaning dirty data removing missing data cleaning outlier finally handle dirty data impact model thats section well see next video",
    "Mod03_Sect05": "hi welcome back module section training section going look select model train data preprocessed point youve done lot clean prepare data doesnt mean data completely ready train algorithm algorithm may able work training data data frame format file format like csv commonly used various algorithm make use optimization file format like record io protobuff use many amazon sagemaker algorithm support training data csv format sagemaker requires csv file doesnt header record target variable first column amazon sagemaker algorithm work best use optimized protobuff record io format training data using format allows take advantage pipe mode training algorithm support using pipe mode training job stream data directly amazon using csv format target variable training data set first column left feature right target variable column evaluating model data trained lead overfitting overfitting model learns particular data set well essentially memorizing training data rather learning relationship feature label mean model isnt learning relationship pattern apply new data future hold split data multiple set set training data validation data testing data training data includes feature label feed algorithm youve selected produce model use model make prediction validation data set youll likely notice thing youll want tweak tune change youre ready run test data set includes feature want label actually predicted performance get test data set reasonably expect see production common split using holdout method using data training set validation test lot data split training validation test small data set use kfold cross validation utilize much data possible still relatively good metric order choose model better kfold cross validation randomly petition data k different segment segment well use rest data outside training order validation particular segment let look example fivefold cross validation available training data separated five different chunk training first model using chunk training data going calculate metric test piece second model going use piece training even model trained apply test piece thing five time use training data test five different model different chunk test data eventually testing data point one thing note splitting data data specific order lead bias model especially true youre working structured data example wine data ordered quality column run model test data ordered pattern applied using model might also mean target missing training data typically randomizing data set prior splitting sufficient many library provide function smaller set sometimes useful use stratified sampling stratified sampling ensures training test set approximately percentage sample target class complete set internet search give many way shuffle split data one easiest use train test split function sk learn amazon sagemaker provides four different way train model builtin algorithm available easily deployed aws console cli jupyter notebook container used behind scene use one amazon sagemaker builtin algorithm deal directly amazon sagemaker supported framework provide prebuilt container support deep learning framework apache mx net tensorflow pytorch chainer also support machine learning library skykit learn spark ml providing prebuilt docker image use amazon sagemaker python sdk deployed using respective amazon sagemaker sdk estimator class prebuilt amazon sagemaker container image use modify advanced scenario package script algorithm use amazon sagemaker use programming language framework develop container example team work build ml model r build container train host algorithm r well one else may already developed tuned model worth looking aws marketplace find available model amazon sagemaker provides high performance scalable machine learning algorithm optimized speed scale accuracy supervised learning amazon sagemaker includes xg boost linear learner algorithm classification quantitative regression problem also factorization machine address recommendation time series prediction problem amazon sagemaker includes support unsupervised learning k mean clustering principal component analysis pca solve problem like identifying customer grouping based purchasing behavior finally selection specialized algorithm processing image deep learning task let look little closer three commonly used built algorithm use case xg boost extreme gradient boosting popular efficient open source implementation gradient boosted tree algorithm gradient boosting supervised learning algorithm attempt accurately predict target variable combining ensemble estimate set simpler weaker model xg boost done remarkably well machine learning competition robustly handle variety data type relationship distribution large number hyperparameters tweaked tuned improved fit flexibility make xg boost solid choice problem regression classification binary multiclass ranking amazon sagemaker linear learner algorithm provides solution classification regression problem amazon sagemaker algorithm simultaneously explore different training objective choose best solution validation set also explore large number model choose best one need compared method provide solution continuous objective amazon sagemaker linear learner algorithm provides significant increase speed naive hyperparameter optimization technique kmeans unsupervised learning algorithm attempt find discrete grouping within data member group similar possible one another different possible member group define attribute want algorithm use determine similarity train model amazon sagemaker create training job training job includes url amazon bucket stored training data url bucket want store output job amazon elastic container registry path training code stored compute resource want amazon sagemaker use model training compute resource ml compute instance managed amazon sagemaker amazon sagemaker provides selection instance type optimized fit different machine learning use case instance type comprise varying combination cpu gpu memory networking capacity give flexibility choose appropriate mix resource building training deploying ml model instance type includes one instance size allowing scale resource requirement target workload key takeaway section module include split data training testing set help validate model accuracy kfold cross validation help smaller data set two key algorithm supervised learning xg boost linear learner use kmeans unsupervised learning use amazon sagemaker train model thats section hope see next video",
    "Mod03_Sect06": "hi welcome back section going look hosting using model section well look deploy trained model consumed application youve trained tuned tested model youll learn testing next section youre ready deploy model youre thinking looking phase order here discussing deployment want test model get performance metric first need make inference prediction model typically requires deployment deployment testing different production although mechanic amazon sagemaker provides everything need host model simple testing evaluation request deployment handling ten thousand request two way deploy model single prediction deploy model amazon sagemaker hosting service sagemaker deploy multiple compute instance run model behind loadbalanced end point application call api end point make prediction model scale number instance based demand get prediction entire dataset use amazon sagemaker batch transform instead deploying maintaining permanent end point sagemaker spin model perform prediction entire dataset provide store result amazon shuts terminates compute instance useful performing batch prediction test model quickly run entire validation set model without writing code process collate individual result goal deployment phase provide managed environment host model providing inference securely low latency model deployed production monitor production data retrain model necessary newly deployed model need reflect current production data new data accumulated time could potentially identify alternative new outcome deploying model onetime exercise instead continuous process one click deploy model amazon ml instance automatically scale across multiple availability zone higher redundancy specify type instance maximum minimum number instance desired sagemaker take care rest launch instance deploy model set secure http endpoint application application need include api call endpoint achieve inference low latency high throughput architecture integrate new model application minute change model longer need change application code sagemaker manages production compute infrastructure behalf perform health check apply security patch conduct routine maintenance builtin amazon cloudwatch monitoring logging whenever youve trained model create endpoint either code using sagemaker console youre planning host single model create endpoint model youre planning host multiple model need create multimodel endpoint multimodel endpoint provide scalable costeffective solution deploying large number model use shared serving container thats enabled host multiple model reduces hosting cost improving endpoint utilization compared using single model endpoint also reduces deployment overhead sagemaker manages loading model memory scaling model based traffic pattern deploy machine learning model production make prediction new data need make sure apply data processing step used training inference request otherwise get incorrect prediction result using inference pipeline reuse data processing step model training inference without maintaining two separate copy code help ensure accuracy prediction reduces development overhead sagemaker managed service inference pipeline completely managed deploy pipeline model service installs run sequence container ec instance endpoint batch transform job additionally sequence feature processing inference run low latency container collated ec instance key takeaway section module include point deploy train model using sagemaker handle api call application perform prediction using batch transformation goal model generate prediction answer business problem sure model generate good result deploy production finally use multimodel endpoint support save resource multiple model deploy thats section well see next video",
    "Mod03_Sect07_part1": "hi welcome back module section well look evaluate model success predicting result point youve trained model time evaluate model determine good job predicting target new future data future instance unknown target value need assess model perform data already know target answer youll use assessment proxy performance future data reason hold sample data evaluating testing important part phase involves choosing appropriate metric business situation think back earlier section problem formulation phase define business problem outcome craft business metric evaluate success model metric choose phase linked business metric much possible there often high correlation two metric addition considering business problem success metric type ml problem youre working influence model metric choose throughout rest module well look example common metric used classification problem well also look common metric used regression problem going start considering simple binary classification problem here specific example imagine simple image recognition model thats labeling data either cat cat model trained use test dataset held back perform prediction help examine performance model compare predicted value actual value plot value table like example start getting insight well model performed confusion matrix get high level comparison predicted class matched actual class actual label class cat identified p positive predicted label class also cat true positive good outcome model similarly actual label cat identified n negative predicted label class also cat true negative also good outcome model case model predicted correct outcome used testing data two possible outcome arent considered good outcome first one actual class negative got cat predicted class positive cat called false positive prediction positive incorrect finally false negative happened actual class positive got cat predicted class negative cat thats part one section well see part two well review calculating classification metric",
    "Mod03_Sect07_part2": "hi welcome back well continue exploring evaluate model diagram show confusion matrix two different model performed data tell one better better isnt good question ask mean better better mean making sure find cat even mean youll get many false positive better mean making sure model accurate difficult see looking two chart youre trying several model using multiple fold hundred data point compare youll need calculate metric first metric sensitivity sometimes referred recall hit rate true positive rate identity percentage positive identification cat example represents percentage cat correctly identified calculate sensitivity take number true positive number positive identification cat divide total number actual cat example cat cat correctly identified cat specificity sometimes referred selectivity true negative rate specificity percentage negative correctly identified cat example number image cat correctly identified cat calculate specificity take number true negative divide total number actual negative example thats number cat correctly identified divided total number actual cat mean example cat identified cat metric model knowing business goal make easier decide model use model would choose wanted make sure youll identify many cat possible model b would good answer youre concerned many false positive youre concerned incorrectly identified cat model would choose wanted make sure identified animal cat model might work scenario would depend many false negative tolerate classification patient heart disease model would best get interesting fun website might get bad reputation cant identify cat correctly youre trying diagnose patient focus probably different important understand tradeoff youre making decide model use also metric help make decision thats part two section well see part three well start looking threshold",
    "Mod03_Sect07_part3": "hi welcome back well continue exploring evaluate model classification model going return probability target value input belonging target class convert value class need determine threshold use might think could change lower higher improve result youve seen sensitivity specificity there tradeoff correctly incorrectly identifying class changing threshold impact outcome going take look visualize receiver operating characteristic graph also known roc graph summarizes confusion matrix threshold produced build one calculate plot sensitivity true positive rate false positive rate graph threshold value calculate false positive rate subtracting specificity one plot point draw line dotted black line mean sensitivity true positive rate equal false positive rate point mean youve correctly identified cat youve also incorrectly identified cat bad point line mean proportion correctly classified sample proportion incorrectly classified sample point represents zero true positive zero false positive model high sensitivity low false positive rate usually goal considered better line threshold recording closer towards top left corner data two model could plot roc curve model compare however tedious there another graph use well look next another evaluation metric use area curve receiver operator curve also known auc roc auc part area plotted line auc higher mean model better predicting cat cat cat cat use auc quickly compare model four number confusion matrix calculate model accuracy also known score adding correct prediction dividing number total number prediction though accuracy widely used metric classification problem limitation metric isnt effective lot true negative case data set think cat cat example accuracy based true negative say model good predicting isnt cat case might feel confident model ability predict cat roll production lead example important make sure metric choose model evaluation aligns business goal think credit card fraud example case using accuracy main metric probably isnt good idea lot true negative high true negative number might hide fact model ability identify case fraud identify true positive isnt ideal credit card company probably unacceptable less almost perfect performance identifying fraud case would drive customer away would opposite youd want achieve business standpoint two metric often used situation first one precision essentially remove negative prediction precision proportion positive prediction actually correct calculate taking true positive dividing true positive plus false positive cost false positive high particular business situation precision might good metric think classification model identifies email message spam case dont want model label email message spam thus prevent user seeing message actually legitimate consider example model need predict whether patient terminal illness case using precision evaluation metric doesnt account false negative model model successful crucial doesnt falsely predict absence illness patient actually illness sensitivity would better metric use situation doesnt always need one f score combine precision sensitivity together give one number quantifies overall performance particular ml algorithm consider using f score class imbalance want preserve equality precision sensitivity youre dealing regression problem case common metric use evaluate model including mean squared error mean squared error frequently used general purpose saw classification metric determine prediction model compare difference prediction actual outcome specifically take difference prediction actual value square difference sum squared difference observation skykit learn use mean squared error function directly metric library metric use linear model r squared youve trained model performed batch transformation test data calculated metric youll use metric help tune model could select different set feature train model retrain model ask better model metric help inform could also use different data retrain model feature remember kfold cross validation earlier module finally could tune parameter model subject next section key takeaway section module evaluate model need data model hasnt seen could either holdout set could use kfold cross validation different machine learning model use different metric classification use confusion matrix aucroc generate regression use mean squared thats section see next video",
    "Mod03_Sect08": "hi welcome back module section section going take look tune model hyperparameters improve model performance recall earlier module hyperparameters thought knob tune machine learning algorithm improve performance looking explicitly tuning model time look specifically different type hyperparameters perform hyperparameter optimization couple different category hyperparameters first kind model hyperparameters help define model example consider neural network computer vision problem case additional attribute architecture need defined like filter size pooling stride padding second kind optimizer hyperparameters relate model learns pattern based data theyre used neural network model type hyperparameters include optimizers like gradient descent stochastic gradient descent also include optimizers use momentum like atom initialize parameter weight method like xavier initialization initialization third kind data hyperparameters relate attribute data include attribute define different data augmentation technique like cropping resizing imagerelated problem theyre often used dont enough data enough variation data tuning hyperparameters labor intensive traditionally done manually someone domain experience related hyperparameter use case person would manually select hyperparameters based intuition experience would train model score validation data process would repeated achieved satisfactory result manual process isnt always thorough efficient way tuning hyperparameters sagemaker perform automated hyperparameter tuning amazon sagemaker automatic model tuning find best version model running multiple training job data set using algorithm hyperparameter range use specify chooses hyperparameter value result model performs best measured metric choose us gaussian process regression predict hyperparameter value might effective improving fit also us bayesian optimization balance exploring hyperparameter space exploiting specific hyperparameter value appropriate importantly automatic model tuning used builtin algorithm sagemaker prebuilt deep learning framework bring algorithm container suppose want solve binary classification problem fraud data set goal maximize area auc curve metric algorithm training linear learner algorithm model dont know value learning rate beta one beta two epoch use train best model find best value hyperparameters specify range value say sagemaker hyperparameter tuning search find combination value result training job performs best measured objective metric chose example sagemaker hyperparameter tuning launch training job use hyperparameter value range specified return training job highest auc hyperparameter tuning might necessarily improve model advanced tool building machine solution considered part scientific method process build complex machine learning system like deep learning neural network exploring possible combination impractical improve optimization use following guideline create hyperparameters first instead using hyperparameters limit number hyperparameters one think would give good result range value hyperparameters choose search significantly affect success hyperparameter optimization although might want specify large range cover every possible value hyperparameter youll get better result limiting search small range value get best metric value within part range consider limiting range part hyperparameter tuning sagemaker attempt figure hyperparameters log scaled linear scaled initially assumes hyperparameters linear scaled log scaled might take time sagemaker discover know hyperparameter log scaled convert improve hyperparameter optimization running hyperparameter tuning job concurrently get work done quickly tuning job improves successive round experiment typically running one training job time achieves best result least amount compute time save distributed training job run multiple instance case hyperparameter tuning us last reported objective metric instance training job value objective metric training job design distributed training job report objective metric want youve gone endtoend process training tuning machine learning model worth talking amazon sagemaker autopilot service help find good model little effort input part autopilot create job supply test training target autopilot analyze data select appropriate feature train tune model document metric find best model based provided data result include winning model metric jupyter notebook use investigate result although using autopilot doesnt remove need preprocess data save time feature selection model tuning key takeaway section module include point first model tuning important finding best solution business problem hyperparameters tuned model optimizer data sagemaker perform automatic hyperparameter tuning finally overall model development accelerated using autopilot thats video see next one",
    "Mod03_WrapUp": "time review module wrap knowledge check module learned formulate problem business request obtain secure data machine learning build jupyter notebook using amazon sagemaker outline process evaluating data using data need preprocessed use open source tool examine preprocess data use amazon sagemaker train host machine learning model use cross validation test performance ml model use hosted model inference create amazon sagemaker hyper parameter tuning job optimize model effectiveness concludes module thanks watching well see next video",
    "Mod04_Intro": "hi welcome module aws academy machine learning module going look forecasting well start introduction forecasting look time series data different kind data going look amazon forecast service help simplify building forecast end module youll able describe business problem solved amazon forecast describe challenge working time series data list step required create forecast using amazon forecast use amazon forecast make prediction see next video",
    "Mod04_Sect01": "hi welcome section well get started reviewing forecasting use case forecasting important area machine learning important many opportunity predicting future outcome based historical data many opportunity involve time component however time component add additional information also make time series problem difficult handle compared type prediction think time series data falling two broad category first type univariate data mean there one variable second one multivariate data mean there one variable several common pattern time series data first pattern trend trend get pattern value increasing decreasing staying time seasonal pattern reflect time year month day pattern cyclical pattern similar seasonal pattern pattern repeat like large retail sale event happens time year finally change data time appear random discernible pattern many us forecasting use forecasting marketing application sale forecasting demand projection could also used inventory management system anticipate required inventory level forecasting energy consumption help predict energy needed weather forecasting system used government commercial application agriculture thats section see next video",
    "Mod04_Sect02_part1": "hi welcome back section going focus processing time series data different type data youve using far time series data data captured chronological sequence defined period time introducing time machine learning model positive impact model derive meaning change data point time time series data tends correlated mean there dependency data point mixed result forecasting youre dealing regression problem regression assumes data point independent need develop method dealing data dependence increase validity prediction addition time series data add related data augmented forecasting model example suppose want make prediction retail sale could include information product sold item identification sale price along number unit sold per time period third type data metadata data set instance say retail data set might want include metadata like brand name genre music video group result better data work multiple data source youll face challenge handling time stamp data youll observe difference time stamp format challenge incomplete data however might able infer missing data case example say data contains month day year observe whether data seems sequence month number database repeating could add year knew data started could infer future year based order data much time stamp data stored utc format data check time stamp local universal time sometimes time stamp doesnt represent time think example suppose database car serviced garage time stamp indicate time car arrived completed picked indicate final entry entered system say youre trying model hourly caloric intake patient however daily data youll need adjust target time scale also data might time stamp could way extrapolate time series depending data domain example might wavelength measurement vector within image final note remember daylight saving different around world also daylight saving time might even occur twice year time zone common occurrence real world forecasting problem missing value raw data missing value make harder model generate forecast primary example retail outofstock situation demand forecasting item go stock sale day zero forecast generated based zero sale value forecast incorrect many reason value marked missing missing value occur transaction also occur possible measurement error example service monitored certain data wasnt working correctly here another example measurement couldnt happen correctly retail primary example inability take correct measurement outofstock situation demand forecasting mean demand doesnt equal sale day several way calculate missing data first method forward fill us last known value missing value moving idea moving average us average last known value calculate missing value backward fill us next known value missing value danger youre using future calculate past bad forecasting method also known look ahead avoided interpolation us equation calculate missing value also use zero fill often used retail missing sale data shouldnt calculated missing data represents order day would wise investigate happened case dont want fill missing value might get data different frequency example might sale data includes exact timestamp sale recorded inventory data contains year month day inventory level data thats different frequency data set data thats compatible question might need sample sampling moving finely grained time less finely grained time example show could converting hourly data set daily data set sampling need decide combine value previous case sale data summing quantity make sense data temperature might want find average understanding data help decide whats best course action opposite sampling sampling move less finely grained time finely grained time problem sampling extremely difficult achieve case suppose want sample sale data daily sale hourly sale unless data source reference wouldnt able case need something perhaps match frequency another time series might irregular time series specific domain knowledge would help case need careful make conversion retail example best could create single order day specified hour temperature could copy daily temperature hourly slot use formula calculate curve data science outlier mix positive negative attribute true time series data suppose examining sale data order unusually high number item might want include forecast calculation order size might never repeated removing outlier anomaly known smoothing removing data help deal outlier anomaly reason might consider smoothing first data preparation remove error value could also remove outlier might also want smooth data generate feature visualization could smooth data reduce noise applaud important understand smoothing data impact might outcome might reduce noise create better model equally important question could smoothing compromise model model expecting noisy data also able smooth data production thats part one section well see part two well review time series specific challenge tool algorithm help u wrangle data",
    "Mod04_Sect02_part2": "hi welcome back well continue exploring wrangling time series data seasonality data kind repeating observation frequency observation stable example sale typically see higher sale end quarter fourth quarter former retail see even higher sale fourth quarter aware data multiple type seasonality data set many time incorporate seasonality information forecast instance localized holiday good example sale chart show total revenue generated arcade strong correlation number computer science doctorate awarded u correlation mean causation disagree see source chart many correlation plotted site none make sense data careful youre seeing acting correlation dont meaning real world here experiment generate two random time series data set number zero one youll find low correlation introduce slope data set youll see strong correlation need know stable system level stability stationarity inform much expect system past behavior inform future behavior system low stability wont successful predicting future youll often want determine trend time series adjust series trend difficult compare another series also adjusted trend trend might dominate value series could lead overestimate correlation two series like discussed previously autocorrelation one special problem face time series data youve seen machine learning problem goal building ml model make sure youre separating signal noise autocorrelation form noise separate observation arent independent time series autocorrelation might overstate accuracy model thats produced algorithm youll look module help correct autocorrelation factor along seasonality influence model youll select produce forecast algorithm handle seasonality autocorrelation others dataswas developed financial data analysis mind good handling time series data first set index pentage data frame date time use date time select data use range contain partial date also extract date part year month weekday name grouping resampling task pentage builtin function finally pentage give insight autocorrelation information pentage time series refer pentage documentation one task building forecasting application choose appropriate algorithm choice algorithm determined type data set youre using feature data set amazon forecast support five algorithm others algorithm handle data slightly different characteristic example take autoregressive integrated moving average also known arima remove autocorrelations influence pattern observation take exponential smoothing also known ets algorithm useful data set seasonality find algorithm amazon forecast documentation key takeaway section module include time series data sequence data includes time element make different regular data set time challenge include dealing different time format handling missing data sampling sampling smoothing dealing seasonality weekday yearly cycle avoiding bad correlation pentage excellent time series support function dealing time five algorithm used amazon forecast arima deepar ets npts profit thats section well see next video",
    "Mod04_Sect02_part3": "hi welcome back section well look use amazon forecast create predictor generate forecast generate forecast apply machine learning development pipeline youve seen throughout course still need data need import much data historical data related data want basic evaluation feature engineering use data train model meet requirement amazon forecast train predictor need choose algorithm youre sure algorithm best data amazon forecast choose select automl algorithm also need select domain data youre sure best fit also select custom domain domain specific type data require trained model use model make forecast using input dataset group youve generated forecast query forecast also export bucket amazon finally encrypt data forecast exporting overall process working amazon forecast import historical related data amazon forecast inspects data identifies key data selects appropriate algorithm us algorithm train optimize custom model produce predictor create forecast applying predictor dataset retrieve forecast aws management console export forecast commadelimited file also use api aws cli command create retrieve forecast work amazon forecast select domain youre working domain ranging retail web traffic there also custom option everything else selecting domain improve efficiency predictor domain specific type data youll supply build predictor example retail domain expects data item identifier timestamp observation number sale item specified timestamp here example data youd need provide retail demand forecast time series need time transaction took place ideally utc format item id item many item sold metadata item might include category item color attribute link back time series data item id item metadata typically doesnt change related data creating useful forecast could include sale price promotion data link back item must include timestamp item id here example data youd need provide web traffic forecast time series need web page id number page view per month timestamp related data creating useful forecast could include page category navigation content category youll also need geographic identifier web plan metadata might also need provide region sale promotion information amazon forecast predictor use algorithm train model use model make forecast using input data set group help get started amazon forecast provides predefined algorithm arima deep ar plus ets npts profit also use automl feature try algorithm see one best predicting data prepare data training machine learning typically hold back data use validate score model data hold back usually random sample available data time series data must process data differently correlation time import data amazon forecast break training test data set diagram show training data used train model tested data held back specify multiple back test window split data multiple time train model use metric determine model give best result default back test window one change amazon forecast split data setting back test window offset parameter create predictor dont set value algorithm use default value youve trained model need measure accuracy youll learn next first amazon forecast evaluation metric weighted quantile loss w quantile loss amazon forecast creates forecast provides probabilistic prediction three distinct quantiles prediction quantiles show much uncertainty associated forecast p quantile predicts time true value less predicted value example suppose retailer want forecast product demand winter glove sell well fall winter say dont sufficient storage space cost invested capital high price overstocked winter glove concern might use p quantile order relatively low number winter glove know p forecast overestimate demand winter glove time youll sold winter glove time p quantile predicts time true value less predicted value continuing winter glove example say know moderate amount demand glove arent concerned overstocked might choose use p quantile order glove p quantile predicts time true value less predicted value suppose determine understocked glove result large amount lost revenue example cost selling glove extremely high cost invested capital low case might choose use p quantile order glove amazon forecast also calculates associated loss error quantile weighted quantile loss calculates far forecast certain quantile actual demand either direction lower w quantile loss metric mean model forecast reliable root mean square error rmsc another method evaluating reliability forecast like w quantile loss rmsc calculates far forecasted value actual test data rmsc find difference actual target value data set forecasted value time period square difference example show calculate rmsc rmsc value represents standard deviation prediction error test good forecast validity error mostly size arent many outlier lower rmsc metric indicate model forecast reliable here example web retailer might use accuracy metric evaluate forecast retailer want predict demand sale particular brand shoe input sale record brand amazon forecast create predictor predictor provides forecasted demand pair p p p value shown weighted quantile loss value indicate time fewer pair sold time fewer pair sold time fewer pair sold retailer use value determine level inventory hold base decision assessment risk wont able fulfill order theyll excess inventory key takeaway section module include use amazon forecast train use model time series data specific schema defined domain retail ec capacity planning use custom schema need supply least time series data also provide metadata related data add information model supervised machine learning problem data split training testing data take account time element use rmse w quantile loss metric evaluate efficiency model thats video well see next one",
    "Mod04_WrapUp": "hi welcome back time review module wrap module learned describe business problem solved amazon forecast describe challenge working time series data list step required create forecast using amazon forecast use amazon forecast make prediction thanks participating see next module",
    "Mod05_Intro": "welcome back aws academy machine learning module great topic today computer vision module well start overview computer vision space youll learn use case terminology next well explore detail analyzing image video managed service amazon web service aws finally well look use customized data set performing object detection end module youll able describe use case computer vision describe amazon managed machine learning service available image video analysis list step required prepare custom data set object detection describe amazon sagemaker ground truth used prepare custom data set finally use amazon recognition perform facial detection thanks watching well see next video",
    "Mod05_Sect01_ver2": "hi welcome back section going introduce computer vision computer vision exciting space machine learning think computer vision automated extraction information digital image using computer vision machine identify people place thing image accuracy thats human level greater speed efficiency computer vision often built deep learning model automates extraction analysis classification understanding useful information single image sequence image image data take many form single image video sequence view multiple camera threedimensional data computing power algorithm advanced last ten year led increase capability easier access computer vision technology computer vision used primary use case computer vision use image facial recognition improve public safety home security way authenticate access personal device also use automatically classify image content management analysis autonomous driving partly enabled computer vision technology safety feature car lane detection collision avoidance medical image analysis computer vision improve accuracy speed patient medical diagnosis result better treatment outcome life expectancy patient finally manufacturing welltrained computer vision incorporated robotics improve quality assurance operational efficiency example probably think computer vision problem broken area content recognition identifying thing image classification problem complex one several layer picture whats represented breakfast lunch dinner would classification food answer depends model use perform classification model must trained training data provides algorithm data learn say model trained picture different type food might expect image output category milk peach mashed potato chicken nugget salad trained model different image could classify object tray cutlery napkin instead work image might want know kind object image location object object detection provides image category object located image there set coordinate defining location box surrounding image known bounding box bounding box detection typically top left width height coordinate surrounding image use coordinate application object detected image there confidence number usually associated object percentage indicates probability object belongs specific class confidence level important want determine action thats based object detection especially facial detection application case action significance object segmentation also known semantic segmentation like object detection go detail get fine boundary detected object basically finegrained inference predicting pixel image application require object segmentation include autonomous vehicle advanced computer human interaction though object segmentation key problem field computer vision wont covering course video add another dimension computer vision video get data work capture movement people object referred instance example detect people enter leave frame also deal moving camera here use case computer vision building detection tracking analyze shopper behavior retail store studying path person follows use face analysis understand detail shopper average age range gender distribution expressed emotion without identifying here another computer vision use case also analyze image identify action using motion video example activity delivering package dancing looking image baseball player example image could include capturing batter accuracy pitcher pitching style type pitch slowball slider others inning batter performance versus specific picture manager could use data coach player improve performance also use data game make game time decision say want initiate various action based speed baseball leaving bat trajectory hit thats calculated ml model could lead audio visual warning possible foul ball crowd could result preemptive alarm hit high probability home run mean event following home run could well timed automated playing music setting firework home run hit home team wrap section key takeaway section first covered computer vision automated extraction information image divide computer vision two distinct area image analysis video analysis image analysis includes object classification detection segmentation video analysis includes instance tracking action recognition motion estimation thanks watching well see next video",
    "Mod05_Sect02_part1_ver2": "welcome back section well explore image analysis detail part two well take closer look video analysis start well introduce main amazon service well using amazon recognition amazon recognition computer vision service thats based deep learning use add image video analysis application many us amazon recognition including creating searchable image video library amazon recognition make image stored video searchable discover object scene appear use amazon recognition build facebased user verification system application confirm user identity comparing live image reference image amazon recognition interprets emotional expression happy sad surprise also interpret demographic information facial image gender amazon recognition also detect inappropriate content image stored video finally amazon recognition recognize extract text content image go here quick note security need check application build using amazon recognition fall regulatory restriction defined field country security compliance amazon recognition shared responsibility aws customer information topic see aws compliance page amazon recognition aws managed service managed service amazon host machine learning model maintains api scale meet demand benefit set model constantly learn improve also focus building application use api optionally training service understand unique business need various resource use access interact amazon recognition apis sdks command aws command line interface also known aws cli language supported sdks include javascript python php net ruby java go nodejs c finally amazon recognition integrates aws service example need storage use amazon simple storage service authentication authorization use aws identity access management also known iam diagram illustrates image search feature user take picture get information real estate property theyre viewing first user take picture mobile device user initiate search cause application upload amazon configured call service write event occurs case bucket pass path new object aws lambda lambda function called us amazon recognition sdk call service amazon recognition analyzes image detects aspect property creates label pass information back lambda object formatted javascript object notation json lambda store label confidence score amazon elastic search service also known amazon e application user identify aspect property using object detected image example architecture system check uploaded image inappropriate content like previous example processing begin user uploads content first user uploads image amazon second bucket configured call lambda function object written bucket third lambda call amazon recognition via sdk amazon recognition analyzes image inappropriate content sends response back lambda fourth content appropriate content approved fifth content isnt appropriate content sent manual inspection finally content isnt approved notification sent user final use case system analyzes video feed sentiment analysis first instore camera capture video thats sent back office cloudbased application typically application like us amazon kinesis stream video second application us sdk send video amazon recognition analysis visual sentiment extracted along attribute age third discovered attribute sent amazon kinesis fourth lambda function extract data stream fifth data written next data loaded amazon redshift regular basis finally tool like amazon quicksight used generate report data amazon recognition designed integrate application api sdks api operation provided detecting label face recognizing celebrity detecting unsafe image perform prediction provide service image object amazon upload byte stream image image jpeg png format amazon recognition process image performs prediction return json object result amazon recognition performs prediction often return multiple label label confidence level confidence level indicates likely label found image like example show label also hierarchy find instance object need understand detected object image instance result amazon recognition include bounding box contains starting coordinate top left box dimension width height like example use information determine location detected object image important note finding contain confidence score use confidence score application tune response prediction higher score likely object correctly labeled thats part one section well see part two well explore facial detection",
    "Mod05_Sect02_part2": "hi welcome back well continue exploring image analysis closer look facial detection facial detection us model tuned perform prediction specifically detecting face facial feature facial detection many feature standard object detection bounding box coordinate box surrounding face detected include value representing confidence bounding box contains face list attribute found face beard appears male female also confidence score attribute also detect physical emotion like whether person smiling frowning important understand classification based visual clue might represent actual emotion person facial landmark component face eye mouth typical landmark also include x coordinate quality describes brightness sharpness face pose describes rotation face inside image confidence feature provided detected feature remember feature prediction based visual observation amazon recognition compare two image determine contain person comparison require source target image result include face found include information matching nonmatching face confidence score indicate likely prediction amazon recognition also search known face use feature need train model providing collection image use train model detect people image provide find known face first create collection add face collection amazon recognition perform facial recognition image provide return typical information like bounding box coordinate confidence score associate face image specify image id external image id request parameter could file name image another id create create collection use search face image operation search face collection return data contains array face matched information includes bounding box confidence score external image id value use id value link back source image youve learned facial detection feature amazon recognition here summary guideline weve discussed far amazon recognition detects human face capture bounding box show face found video also detect attribute position eye nose mouth detect emotion quality detection landmark might appear item associated confidence score higher score mean model greater confidence detection gender inferred image inferred identity similarly emotion also determined image might reflect subject actual emotional state apply facial recognition responsibly facial recognition never used way violates individual right including right privacy also never used make autonomous decision scenario require human analyze example suppose bank us tool like amazon recognition financial application verify customer identity bank always clearly disclose use technology ask customer approve term condition information topic see aws webpage fact facial recognition artificial intelligence well explain use amazon recognition process video perform video processing stored video video stream stored video uploaded stored bucket type detection start operation search people face label celebrity text inappropriate content amazon recognition publishes completion status topic amazon simple notification service also known amazon sn sn route message subscriber durability best practice route message message queue amazon simple queue service amazon sqs application monitor sqs queue completion start operation corresponding get operation retrieving result call get detection result return array label contain information label found video label information includes label image detection also includes timestamp label detected millisecond start video addition stored video also use amazon recognition video detect recognize face streaming video typical use case detecting known face video stream amazon recognition video us amazon kinesis video stream receive process video stream analysis result output amazon recognition video kinesis data stream read client application amazon recognition video provides stream processor thats called create stream processor use start manage analysis streaming video use amazon recognition video streaming video application must implement resource first need kinesis video stream send streaming video amazon recognition video next need amazon recognition video stream processor manage streaming video analysis finally need kinesis data stream consumer read analysis result amazon recognition video sends data stream want find face video need create collection process creating collection still image amazon recognition video place json frame record analyzed frame kinesis output stream amazon recognition video doesnt analyze every frame thats passed kinesis video stream frame record sent kinesis data stream contains information video stream fragment frame frame fragment face recognized frame also includes status information stream processor wrap here quick summary amazon recognition computer vision service thats based deep learning easily add image video analysis application amazon recognition detect face sentiment text unsafe content library search image video amazon recognition integrated aws service thanks watching well see next video",
    "Mod05_Sect03_part1": "section well look preparing custom data set computer vision detect custom object one challenge using prebuilt model find image trained find though amazon recognition trained ten million image cant detect object wasnt trained example consider heart playing card run card amazon recognition result show various attribute however none label playing card heart want amazon recognition detect image problem domain must train model image section youll learn train amazon recognition image problem domain though youll focus using amazon recognition youll encounter similar process use pretrained model training computer vision algorithm recognize image requires large input data set isnt practical organization many machine learning problem today solved training existing model use managed service like amazon recognition custom label like machine learning process need train amazon recognition recognizes scene object specific domain youll need training data set test data set contain labeled image image need label use amazon recognition custom label simplify labeling task example provides ui labeling image includes feature use draw bounding box around image also help find object scene unique business need use classify image detect object within image say want identify specific machine part image turbochargers torque converter could collect picture kind machine part use train model amazon recognition custom label also includes automated machine learning capability handle machine learning process provide training image service automatically load inspect data select correct machine learning algorithm train model provide model performance metric finish training model evaluate custom model performance test set image test set sidebyside comparison model prediction versus label assigned also detailed performance metric review start using model immediately image analysis iterate retrain new version image refine model start using model track prediction correct mistake use feedback data retrain new model version improve performance label image diagram show typical process training computer vision model includes amazon recognition custom label feature well step detail process developing custom model analyze image requires time expertise resource often take month complete also require thousand ten thousand handlabeled image model enough data make accurate decision take month generate gather data require large team lablers prepare use machine learning amazon recognition custom label build existing capability amazon recognition already trained ten million image across many category instead thousand image upload small set training image specific use case typically youd use hundred image use aws management console upload training image image already labeled amazon recognition custom label begin training model theyre label image directly labeling interface use amazon sagemaker ground truth label theyll shortly amazon recognition custom label work best use different model different domain example need detect machine part plant health youd use two different model use use select training similar image used inference use image use various lighting condition background resolution ideally training image mirror image youd want perform detection use source like youd use production work best documentation includes additional guideline image type whether jpegs pngs property like image size resolution thats part one section well see part two well review create training data set",
    "Mod05_Sect03_part2": "hi welcome back well continue exploring video analysis reviewing create training data set data set contain information thats needed train test amazon recognition custom label model image label bounding box use image amazon upload computer part process train model data set least two label least ten image per label image data set must labeled mentioned earlier use amazon recognition custom label console amazon sagemaker ground truth label image train amazon recognition custom label model image must labeled label indicates image contains object scene concept mentioned earlier data set need least two defined label also image must least one assigned label identifies object scene concept image apply label image whole label known imagelevel label theyre useful identifying scene concept want detect example one image show beach scene coalina island oahu u state hawaii train model detect beach youd add beach label applies entire image also apply label specific area image contain object want detect example want model detect amazon echo device must identify different type echo device image model need information device located image need corresponding label identifies type device information known localization information location device expressed bounding box example object bounding box image show bounding box surround amazon echo dot image also contains amazon echo without bounding box output labeling process manifest file manifest file imagelevel label typically contains label class name along metadata image labeled object detection manifest contains information labeled image bounding box identifies object image along label bounding box belongs weve mentioned amazon sagemaker ground truth time well look might help sagemaker ground truth build high quality training datasets machine learning model use create dataset need labeling provide detailed instruction need labeled submit job decide process image create label dataset use worker amazon mechanical turk service vendor company internal workforce machine learning use label dataset output sagemaker ground truth train model also use amazon recognition custom label sagemaker ground truth use active learning automate labeling input data active learning machine learning technique identifies data labeled worker sagemaker ground truth functionality called automated data labeling automated data labeling reduce time cost take label dataset compared using human worker use automated labeling incur amazon sagemaker training inference cost yes said use machine learning label image youll use machine learning well talk work sagemaker ground truth start automated data labeling job selects random sample input data object sends human worker label data returned sagemaker ground truth us data validation data validate model trained automated data labeling sagemaker ground truth run batch transform job using validated model inference validation data batch inference produce confidence score quality metric object validation data automated labeling determines confidence score object produced step five meet required threshold determined step four confidence score meet threshold expected quality automatic labeling exceeds requested level accuracy object considered automatically labeled step six produce data set unlabeled data confidence score sagemaker ground truth selects data point low confidence score data set sends human worker additional labeling sagemaker ground truth us existing human labeled data additional human labeled data train new model process repeated data set fully labeled another stopping condition met example automatic labeling stop meet budget human annotation recommend using automated data labeling large data set minimum number object allowed automated data labeling however strongly suggest providing minimum object thats part two section well see part three well review evaluate improve model",
    "Mod05_Sect03_part3": "hi welcome back well continue exploring video analysis reviewing create test data set final step train model identify test data set use test data set validate evaluate model performance youll performing inference image test data set youll compare result labeling information thats training data set create test data set alternatively use amazon recognition custom label split training data set two data set using split split mean data used training used testing define training test data set amazon recognition custom label automatically train model service automatically load inspects data select correct machine learning algorithm train model provides model performance metric charge amount time model take train data set contains image label take longer train training complete evaluate performance model testing amazon recognition custom label predicts test image contains custom label confidence score value quantifies certainty model prediction classification problem result mapped confusion matrix true positive model correctly predicts presence custom label test image predicted label also ground truth label image example amazon recognition custom label correctly return cat label cat present image false positive model incorrectly predicts presence custom label test image predicted label isnt ground truth label image example amazon recognition custom label return cat label there cat label ground truth image false negative model doesnt predict custom label present image ground truth image includes label example amazon recognition custom label doesnt return cat custom label image contains cat true negative model correctly predicts custom label isnt present test image example amazon recognition custom label doesnt return cat label image doesnt contain cat console provides access true positive false positive false negative value image test data set prediction result used calculate various metric label aggregate metric entire test set definition apply prediction model make bounding box level bounding box metric calculated bounding box test image regardless whether box prediction ground truth help amazon recognition custom label provides various metric example view summary metric evaluation metric label also provides precision metric label average precision metric entire test data set precision proportion positive result correctly classified amazon recognition custom label provides average recall metric label average recall metric entire test data set recall fraction test set label correctly classified using previous example cat would many cat correctly classified service also provides average model performance score label average model performance score entire test data set f score combine precision recall together give one number quantifies overall performance particular machine learning algorithm might use f score class imbalance also want preserve equality precision sensitivity higher value mean better model performance recall precision youre satisfied accuracy model start using thats part three section well see part four well review evaluate improve model",
    "Mod05_Sect03_part4_ver2": "hi welcome back well continue exploring video analysis reviewing evaluate improve model general improve quality model larger quantity better quality data use training image clearly show object scene dont include many thing youre interested bounding box around object use training image show object fully visible hidden object make sure training test data set match type image youll eventually run inference object training example like logo provide bounding box around logo test image image represent scenario want localize object reducing false positive often result better precision reduce false positive first check increasing confidence threshold enables keep correct prediction eliminating false positive increasing confidence threshold eventually result diminishing gain tradeoff precision recall given model next check see need add additional class training example detecting cat often dog flagged cat add dog label training data set along image dog got false positive effectively youre helping model learn predict dog cat new training image might find model confused two custom label cat dog test image label cat predicted labeled dog vice versa case first check mislabeled image training test set also adding training image reflect confusion help retrain model learn better discriminate cat dog using false negative often result better recall reduce false negative first lower confidence threshold improve recall also use better example model variety object image appear finally split label two class easier learn example instead good cooky bad cooky might want good cooky burnt cooky broken cooky help model learn unique concept better youre satisfied performance model make available use starting console using code model running perform inference aws cli sdk call api specify amazon resource name amazon recognition custom label model want use amazon resource name also known arn youll also specify image want model make prediction provide input image image byte array base encoded image byte object custom label returned array custom label object custom label represents single object scene concept thats found image custom label includes label object scene concept found image also includes bounding box object found image bounding box coordinate show object located source image coordinate value ratio overall image size finally custom label includes confidence score represents confident amazon recognition custom label accuracy label bounding box training model calculates threshold value determines prediction label true default detect custom label operation doesnt return label confidence value thats less model calculated threshold value filter returned label specify value min confidence thats greater model calculated threshold get model calculated threshold model training result amazon recognition custom label console get label regardless confidence specify min confidence value zero find confidence value returned detect custom label operation low consider retraining model restrict number custom label returned detect custom label operation specifying max result input parameter returned result sorted highest confidence lowest confidence key takeaway section module model must trained specific domain want analyze youre looking turbochargers youll need many picture turbochargers train model set custom labeling specific business case looked custom labeling process tool use want object detected need label image create bounding box object use amazon sagemaker groundtruth build training data set model also use machine learning label image thanks watching well see next video",
    "Mod05_WrapUp_ver2": "time summarize main point module module learned describe use case computer vision describe amazon managed machine learning service available image video analysis list step required prepare custom data set object detection describe amazon sagemaker ground truth used prepare custom data set use amazon recognition perform facial detection concludes introduction computer vision thanks watching well see next video",
    "Mod06_Intro": "hi welcome module aws academy machine learning introduction natural language processing module well introduce natural language processing also known nlp section includes description major challenge faced nlp overall development process nlp application well review five aws service use speed development nlpbased application completing module able describe nlp use case solved using managed amazon ml service describe managed amazon ml service available nlp let get started",
    "Mod06_Sect01": "well get started reviewing natural language processing mean natural language processing also known nlp explain nlp well consider example nlp amazon alexa alexa work device amazon echo record word recording speech sent amazon server analyzed efficiently amazon break phrase individual sound connects database containing pronunciation various word find word closely correspond combination individual sound amazon identifies important word make sense task carry corresponding function instance alexa notice word like outside temperature open weather alexa skill amazon server send information back device alexa speaks nlp broad term general set business computational problem solve machine learning ml however nlp system predate machine learning example speech text older presmart phone cell phone used nlp screenreaders many nlp system use form machine learning nlp considers hierarchical structure language word lowest layer hierarchy group word make phrase next level phrase make sentence ultimately sentence convey idea nlp system face several significant challenge well look challenge next language isnt precise word different meaning based word surround known context often word phrase multiple meaning example consider term weather could weather colloquial meaning english youre sick could say there wonderful weather outside mean weather condition outside good phrase oh really could convey surprise disagreement many thing depends context inflection main challenge nlp one challenge discovering structure text one first task nlp application break text meaningful unit word phrase sentence another challenge labeling data system convert text data must apply label representing various part speech every language require different labeling scheme match language grammar nlp also face challenge representing context word meaning depend heavily context nlp system need way represent large challenge many context difficult convert context form computer understand finally although grammar defines structure language application grammar indescribably large scope handling variation language used human major challenge nlp system thats machine learning large impact apply nlp range problem common application include search application google bing common machine interaction like alexa sentiment analysis marketing political campaign social research based medium analysis chatbots mimic human speech application apply machine learning development pipeline youve seen throughout course developing nlp solution first task formulate problem collect label data nlp collecting data consists breaking text meaningful subset labeling set feature engineering major part nlp application process get complicated youre dealing highly irregular unstructured text example say youre building application classify document youd need able distinguish word common term different meaning labeling data nlp domain sometimes also called tagging labeling process assign individual text string different part speech specialized tool use nlp labeling first task nlp application convert text data analyzed convert text removing word arent needed analysis input text example word removed leave phrase sample text removing stop word normalize text converting similar word common form example word run runner ran running different form word run normalize instance word block text using stemming limitization process limitization group different form word single term limitization version word run would group instance form single term run stemming hand remove character stemming algorithm considers unnecessary might work run example form ran might recognized form word run youve normalized text standardize removing word arent dictionary youre using analysis example could remove acronym slang special character natural language toolkit also known nltk python library provides function removing stop word normalizing text another first step creating nlp system convert text data collection data frame nlp library provide function assist process example show using word tokenize function nltk library youve cleaned text loaded data frame apply one nlp model create feature couple common model first model known bag word simple model capturing frequency word document model creates key word value key number time word occurs document second model term frequency inverse document frequency also known tf idf term frequency count many time word appears document inverse document frequency number time word occurs group document two value used together calculate weight word many established model nlp field example show bag word model bag word vector model vector model convert sentence phrase vector mathematical object record directionality magnitude example simple sentence converted vector frequency word recorded word value two appears twice sentence bag word often used classify document different category also used derive attribute feed nlp application sentiment analysis three broad category text analysis first classification text similar classification system youve seen course text provides input process extract feature send feature machine learning algorithm interacts classifier model infers classification many application text matching example autocorrect spelling grammar checking based text matching algorithm edit distance also known levinstein distance frequently used derive relationship different word phrase text using process called coreference resolution several nlp system provide python library deriving relationship one biggest challenge nlp describe context text user searching term tablet word tablet least two distinct meaning search engine need know meaning user mind search engine rely commonly used context term isnt qualified example adding another term like medicine computing search process extracting entity known named entity recognition ner ner model following function first identify noun phrase using dependency chart part speech tagging classify phrase using classification algorithm word veck finally disambiguate entity using knowledge graph here example using ner extract entity titanic north atlantic text named entity extracted use knowledge graph extract meaning knowledge graph combine subjectmetare expertise machine learning derive meaning amazon recommendation engine example knowledge graph main point remember section first nlp predates machine learning use ml workflow youve seen module nlp main use case nlp search query analysis human machine interaction marketing social research nlp complicated human language lack precision thanks watching well see next video",
    "Mod06_Sect02": "welcome back section well review five managed machine learning service use various use case service simplify process creating machine learning application well start looking amazon transcribe use amazon transcribe recognize speech audio file produce transcription recognize specific voice audio file create customized vocabulary term specialized particular domain also add transcription service application integrating web socket internet protocol use twoway communication application amazon transcribe common use case amazon transcribe first medical professional record note amazon transcribe capture spoken note text also video production organization generate subtitle automatically video could also done real time live feed add closed captioning medium company use amazon transcribe capture label content feed content amazon comprehend analysis last company record customer service sale call transcribe analyze result training strategic opportunity amazon poly convert text lifelike speech input either plain text file file thats formatted speechsynthesis markup language ssml ssml markup language used provide special instruction speech sound example want introduce pause flow speech add ssml tag instructs amazon poly pause two word also output speech amazon poly mp vorbis pcm audio stream format amazon poly eligible use certain regulated workload example eligible use u health insurance portability accountability act hipaa amazon poly also eligible use payment card industry data security standard pci ds common use case amazon poly first example major news company using amazon poly generate vocal content directly written story also embedded mapping apis developer add voice geobase application language training company used amazon poly create system learning new language finally animator used add voice character amazon translate create multilanguage experience application create system read document one language render store another language also use part document analysis system amazon translate fully integrated machine learning service amazon comprehend amazon transcribe amazon poly integration extract named entity sentiment key phrase integrating amazon comprehend create multilingual subtitle amazon transcribe speak translated content amazon poly common use case amazon translate first use case building international website use amazon translate quickly globalize website amazon translate also used develop multilingual chatbots chatbots used create humanlike interface application amazon translate create chatbot speaks multiple language another use case software localization translation major cost software aimed global audience amazon translate decrease software development time significantly reduce cost localizing software final example use case international medium management company manage medium global audience used amazon translate reduce cost localization amazon comprehend implement many nlp technique reviewed earlier module extract key entity perform sentiment analysis tag word part speech common use case amazon comprehend first example analyzing legal medical document legal insurance medical organization used amazon comprehend perform many nlp function reviewed module another use largescale mobile app analysis mobile app developer use amazon comprehend look pattern usage apps design improvement financial fraud detection another use case amazon comprehend banking financial institution used examine large data set financial transaction uncover fraud look pattern illegal transaction finally used content management medium content company use amazon comprehend tag content analysis management amazon lex add human language front end application amazon lex let use conversational engine power amazon alexa automatically increase capacity amazon lex solution creating aws lambda function scale demand also store log file conversation analysis common use case amazon lex first use case building front end interface inventory management sale three interface becoming common company used amazon lex add chatbots inventory sale application another use amazon lex creating customer service interface humanlike voice application quickly becoming standard many customer service application amazon lex reduce time take develop chatbots increase quality amazon lex also used develop interactive assistance combining amazon lex ml service customer creating sophisticated assistance many different industry final example use case querying database humanlike language amazon lex combined aws database service create sophisticated data analysis application humanlike language interface main point take away module first amazon transcribe automatically convert spoken language text amazon poly convert written text spoken language amazon translate create realtime translation language amazon comprehend automates many nlp use case reviewed module finally amazon lex create humanlike interface application thanks watching well see next video",
    "Mod06_WrapUp": "welcome back time review module wrap summary module learn describe nlp use case solved using managed amazon ml service describe managed ml service available nlp good job thanks watching well see next module",
    "Mod07_Sect01": "welcome module course wrap congratulation completing aws academy machine learning course well take minute review youve learned go going start review youve learned course learned describe machine learning implement machine learning pipeline use amazon machine learning service forecasting computer vision natural language processing well done although course isnt designed prepare become certified aws certified machine learning specialty well review continue work towards certification aws certification help build credibility confidence validating cloud expertise industryrecognized credential also help organization identify skilled professional lead cloud initiative using aws must earn passing score taking proctored exam earn aws certification receiving passing score youll receive certification credential aws certification doesnt publish list service feature covered certification exam however there exam guide exam list current topic area objective covered exam exam guide found prepare aws certification exam webpage youll required update certification recertify every three year view aws certification recertification page detail information slide current june however exam frequently updated also detail regarding exam available topic tested exam subject change aws certified machine learning specialty mean select justify appropriate machine learning approach given business problem also identify appropriate aws service implement machine learning solution finally design implement scalable costoptimized reliable secure machine learning solution sitting aws certified machine learning specialty exam recommend following knowledge experience first one two year experience developing architecting running ml deep learning workload aws cloud experience include performing basic hyperparameter optimization working machine learning deep learning framework also able express intuition behind basic ml algorithm finally able follow best practice model training addition best practice deployment operation thanks watching congratulation completing aws academy machine learning course"
}